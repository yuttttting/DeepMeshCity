{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c64ea29",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f941ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class Dataset_TPE(Dataset):\n",
    "    def __init__(self, configs, mode):\n",
    "        self.datapath = configs.datapath\n",
    "        self.data_type = configs.data_type\n",
    "        self.max_value = configs.max_value\n",
    "        if mode == 'train':\n",
    "            self.name = 'train_' + self.data_type + '.npz'\n",
    "        elif mode == 'valid':\n",
    "            self.name = 'valid_' + self.data_type + '.npz'\n",
    "        else:\n",
    "            self.name = 'test_' + self.data_type + '.npz'\n",
    "        path = os.path.join(self.datapath, self.name)\n",
    "        self.data = self.load_data(path)\n",
    "\n",
    "    def load_data(self, path):\n",
    "        all_data = np.load(path)\n",
    "        self.XC = all_data['xc']\n",
    "        self.XP = all_data['xp']\n",
    "        self.XT = all_data['xt']\n",
    "        self.YS = all_data['ys']\n",
    "        self.YD = all_data['yd']\n",
    "\n",
    "        print(self.XC.shape, self.XP.shape, self.XT.shape, self.YS.shape, self.YD.shape, self.max_value)\n",
    "\n",
    "        return all_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data['xc'].shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        XC = torch.FloatTensor(self.XC[item])\n",
    "        XP = torch.FloatTensor(self.XP[item])\n",
    "        XT = torch.FloatTensor(self.XT[item])\n",
    "        YS = torch.FloatTensor(self.YS[item])\n",
    "        YD = torch.FloatTensor(self.YD[item])\n",
    "\n",
    "        return XC, XP, XT, YS, YD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee745b86",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7d0e5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CGL(nn.Module):\n",
    "    def __init__(self, in_channel, num_hidden, filter_size, stride, is_norm):\n",
    "        super(CGL, self).__init__()\n",
    "\n",
    "        self.num_hidden = num_hidden\n",
    "        self.padding = filter_size // 2\n",
    "        self.forget_bias = -1.0\n",
    "\n",
    "        if is_norm:\n",
    "            self.conv_x = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, num_hidden * 4, kernel_size=filter_size, stride=stride, padding=self.padding),\n",
    "                nn.GroupNorm(num_hidden // 2, 4 * num_hidden)\n",
    "            )\n",
    "            self.conv_c = nn.Sequential(\n",
    "                nn.Conv2d(num_hidden, num_hidden * 2, kernel_size=filter_size, stride=stride, padding=self.padding),\n",
    "                nn.GroupNorm(num_hidden // 2, num_hidden * 2)\n",
    "            )\n",
    "\n",
    "            self.conv_m = nn.Sequential(\n",
    "                nn.Conv2d(num_hidden, num_hidden * 2, kernel_size=filter_size, stride=stride, padding=self.padding),\n",
    "                nn.GroupNorm(num_hidden // 2, num_hidden * 2)\n",
    "            )\n",
    "            self.conv_o_c = nn.Sequential(\n",
    "                nn.Conv2d(num_hidden * 2, num_hidden, kernel_size=1, stride=1, padding=0),\n",
    "                nn.GroupNorm(num_hidden // 2, num_hidden)\n",
    "            )\n",
    "        else:\n",
    "            self.conv_x = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, num_hidden * 4, kernel_size=filter_size, stride=stride, padding=self.padding),\n",
    "            )\n",
    "            self.conv_c = nn.Sequential(\n",
    "                nn.Conv2d(num_hidden, num_hidden * 2, kernel_size=filter_size, stride=stride, padding=self.padding),\n",
    "            )\n",
    "            self.conv_m = nn.Sequential(\n",
    "                nn.Conv2d(num_hidden, num_hidden * 2, kernel_size=filter_size, stride=stride, padding=self.padding),\n",
    "            )\n",
    "            self.conv_o_c = nn.Sequential(\n",
    "                nn.Conv2d(num_hidden * 2, num_hidden, kernel_size=filter_size, stride=stride, padding=self.padding),\n",
    "            )\n",
    "\n",
    "        self.conv_last = nn.Conv2d(num_hidden * 2, num_hidden, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x_t, c_t, m_t):\n",
    "        x_concat = self.conv_x(x_t)\n",
    "        m_concat = self.conv_m(m_t)\n",
    "        c_concat = self.conv_c(c_t)\n",
    "\n",
    "        x_p, f_x, x_m_p, f_m_x = torch.split(x_concat, self.num_hidden, dim=1)\n",
    "        f_m, g_m = torch.split(m_concat, self.num_hidden, dim=1)\n",
    "        f_c, g_c = torch.split(c_concat, self.num_hidden, dim=1)\n",
    "\n",
    "        f_t = torch.sigmoid(f_x + f_c + self.forget_bias)\n",
    "        x_p_t = torch.tanh(x_p + g_c)\n",
    "\n",
    "        c = f_t * c_t + (1 - f_t) * x_p_t\n",
    "\n",
    "        f_t_prime = torch.sigmoid(f_m_x + f_m + self.forget_bias)\n",
    "        g_t_prime = torch.tanh(x_m_p + g_m)\n",
    "\n",
    "        m = f_t_prime * m_t + (1 - f_t_prime) * g_t_prime\n",
    "\n",
    "        mem = torch.cat((c, m), 1)\n",
    "\n",
    "        o_t = torch.sigmoid(self.conv_o_c(mem))\n",
    "        h_new = o_t * torch.tanh(self.conv_last(mem))\n",
    "\n",
    "        return h_new, c, m\n",
    "\n",
    "\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_szie=1):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.layer_q = nn.Conv2d(input_dim, hidden_dim, kernel_szie)\n",
    "        self.layer_k = nn.Conv2d(input_dim, hidden_dim, kernel_szie)\n",
    "        self.layer_v = nn.Conv2d(input_dim, hidden_dim, kernel_szie)\n",
    "        self.layer_f = nn.Conv2d(hidden_dim, input_dim, kernel_szie)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def forward(self, q, k, v, extra=None):\n",
    "        batch_size, channel, H, W = q.shape\n",
    "        h = q  # short connection\n",
    "\n",
    "        q = self.layer_q(q)\n",
    "        k = self.layer_k(k)\n",
    "        v = self.layer_v(v)\n",
    "\n",
    "        if extra is not None:\n",
    "            # 外部特徵 encode 成 attention bias\n",
    "            # extra shape: (B, M, H, W)\n",
    "            extra_flat = extra.view(batch_size, -1, H * W)\n",
    "            q = q + extra_flat.mean(dim=1, keepdim=True).unsqueeze(-1)  # broadcast to q shape\n",
    "            k = k + extra_flat.mean(dim=1, keepdim=True).unsqueeze(-1)\n",
    "\n",
    "        q = q.view(batch_size, self.hidden_dim, H * W)\n",
    "        k = k.view(batch_size, self.hidden_dim, H * W)\n",
    "        v = v.view(batch_size, self.hidden_dim, H * W)\n",
    "\n",
    "        attn = torch.matmul(q.transpose(1, 2), k)\n",
    "        # print('e shape is', e.shape)\n",
    "        attention = torch.softmax(attn, dim=-1)  # attention\n",
    "        z = torch.matmul(attention, v.permute(0, 2, 1))\n",
    "        z = z.view(batch_size, self.hidden_dim, H, W)\n",
    "        out = self.layer_f(z) + h\n",
    "\n",
    "        return out, attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d10e6c",
   "metadata": {},
   "source": [
    "# DeepMeshCity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9afaf2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "\n",
    "class DeepMeshCity(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(DeepMeshCity, self).__init__()\n",
    "        # hyperparrams\n",
    "        self.meta_in = configs.meta_dim\n",
    "        self.map_width = configs.map_width\n",
    "        self.patch_size = configs.patch_size\n",
    "        self.resize_ratio = self.map_width // self.patch_size\n",
    "        self.frame_channel = configs.map_channel\n",
    "        self.clossness_len = configs.clossness_len\n",
    "        self.periodic_len = configs.periodic_len\n",
    "        self.trend_len = configs.trend_len\n",
    "        self.device = configs.device\n",
    "\n",
    "        # Parameter for External Meta data\n",
    "        self.meta_out = self.map_width * self.map_width * self.frame_channel\n",
    "        self.is_metadate = configs.is_metadate\n",
    "        self.Meta_frame_channel = self.frame_channel * 2 if self.is_metadate else self.frame_channel\n",
    "        self.is_extra = configs.is_extra \n",
    "\n",
    "        # Parameter for Model\n",
    "        self.num_layers = configs.num_layers\n",
    "        self.num_hidden = configs.num_hidden\n",
    "        self.filter_size = configs.filter_size\n",
    "        self.stride = configs.stride\n",
    "        self.layer_norm = configs.layer_norm\n",
    "\n",
    "        # Early Fusion\n",
    "        if self.is_metadate:\n",
    "            self.meta_learn = nn.Sequential(nn.Linear(self.meta_in, 10),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Linear(10, self.meta_out),\n",
    "                                            nn.ReLU())\n",
    "        # if self.is_extra:\n",
    "        #     self.extra = # todo\n",
    "        \n",
    "        # Stacked SA-CGL Blocks\n",
    "        SACGL_blocks = []\n",
    "        for i in range(self.num_layers):\n",
    "            in_channel = self.Meta_frame_channel if i == 0 else self.num_hidden[i - 1]\n",
    "            attn_channel = in_channel * self.resize_ratio * self.resize_ratio\n",
    "            SACGL_blocks.append(nn.ModuleList([\n",
    "                self_attention(attn_channel, self.num_hidden[i]),\n",
    "                CGL(in_channel, self.num_hidden[i], self.filter_size, self.stride, self.layer_norm)\n",
    "            ]))\n",
    "\n",
    "        self.SACGL_blocks = nn.ModuleList(SACGL_blocks)\n",
    "\n",
    "        # Output Module\n",
    "        self.Output_module = nn.Sequential(\n",
    "            nn.Conv2d(self.num_hidden[self.num_layers - 1], self.num_hidden[-1],\n",
    "                      kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(self.num_hidden[-1], self.frame_channel,\n",
    "                      kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        )\n",
    "    def Attention_module(self, net, i, extra=None):\n",
    "        net = rearrange(net, 'b c (p1 h) (p2 w) -> b (h w c) p1 p2', p1=self.patch_size, p2=self.patch_size)\n",
    "        if extra is not None:\n",
    "            extra = rearrange(extra, 'b c (p1 h) (p2 w) -> b (h w c) p1 p2', p1=self.patch_size, p2=self.patch_size)\n",
    "        \n",
    "        net, _ = self.SACGL_blocks[i][0](net, net, net, extra)\n",
    "        net = rearrange(net, 'b (h w c) p1 p2 -> b c (p1 h) (p2 w)', h=self.resize_ratio, w=self.resize_ratio)\n",
    "\n",
    "        return net\n",
    "\n",
    "    def forward(self, xc, xp, xt, yd):\n",
    "        B, _, C, H, W = xc.shape\n",
    "\n",
    "        if self.is_metadate:\n",
    "            if yd.dim() > 2:\n",
    "                yd = yd.view(yd.shape[0], -1)\n",
    "            \n",
    "            yd = rearrange(self.meta_learn(yd), 'b (f c h w) -> b f c h w', c=self.frame_channel,\n",
    "                           h=self.map_width, w=self.map_width)\n",
    "\n",
    "            xcd = yd.repeat(1, self.clossness_len, 1, 1, 1) if self.clossness_len > 1 else yd\n",
    "            xpd = yd.repeat(1, self.periodic_len, 1, 1, 1) if self.periodic_len > 1 else yd\n",
    "            xtd = yd.repeat(1, self.trend_len, 1, 1, 1) if self.trend_len > 1 else yd\n",
    "\n",
    "            xp = torch.cat((xp, xpd), dim=2)\n",
    "            xt = torch.cat((xt, xtd), dim=2)\n",
    "            xc = torch.cat((xc, xcd), dim=2)\n",
    "\n",
    "        frames = torch.cat((xt, xp, xc), dim=1)\n",
    "\n",
    "        batch = frames.shape[0]\n",
    "        height = frames.shape[-2]\n",
    "        width = frames.shape[-1]\n",
    "\n",
    "        h_t = []\n",
    "        c_t = []\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            zeros = torch.zeros([batch, self.num_hidden[i], height, width]).to(self.device)\n",
    "            h_t.append(zeros)\n",
    "            c_t.append(zeros)\n",
    "\n",
    "        memory = torch.zeros([batch, self.num_hidden[0], height, width]).to(self.device)\n",
    "\n",
    "        total_length = self.clossness_len + self.periodic_len + self.trend_len\n",
    "        for t in range(total_length):\n",
    "            net = frames[:, t]\n",
    "\n",
    "            net = self.Attention_module(net, 0, extra=self.is_extra)\n",
    "            \n",
    "            h_t[0], c_t[0], memory = self.SACGL_blocks[0][1](net, c_t[0], memory)\n",
    "\n",
    "            for i in range(1, self.num_layers):\n",
    "                h_t[i - 1] = self.Attention_module(h_t[i - 1], i, extra=self.is_extra)\n",
    "                h_t[i], c_t[i], memory = self.SACGL_blocks[i][1](h_t[i - 1], c_t[i], memory)\n",
    "\n",
    "        x_gen = self.Output_module(h_t[self.num_layers - 1])\n",
    "        return x_gen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b631bd",
   "metadata": {},
   "source": [
    "# model_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6382fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(configs):\n",
    "    networks_map = {\n",
    "        'DeepMeshCity_TPE': DeepMeshCity,\n",
    "    }\n",
    "    model_type = configs.model_type\n",
    "\n",
    "    if model_type in networks_map:\n",
    "        Network = networks_map[model_type]\n",
    "        network = Network(configs).to(configs.device)\n",
    "        return network\n",
    "    else:\n",
    "        raise ValueError('Name of network unknown %s' % model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be8c7c8",
   "metadata": {},
   "source": [
    "# grid in csv to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1edd98f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grid_271', 'grid_300', 'grid_301', 'grid_188', 'grid_302', 'grid_189', 'grid_303', 'grid_299', 'grid_216', 'grid_217', 'grid_331', 'grid_218', 'grid_215', 'grid_244', 'grid_245', 'grid_246', 'grid_272', 'grid_247', 'grid_273', 'grid_274', 'grid_275', 'grid_243', 'grid_420', 'grid_416', 'grid_417', 'grid_418', 'grid_419', 'grid_447', 'grid_308', 'grid_304', 'grid_305', 'grid_306', 'grid_307', 'grid_392', 'grid_388', 'grid_389', 'grid_390', 'grid_391', 'grid_386', 'grid_387', 'grid_414', 'grid_415', 'grid_276', 'grid_277', 'grid_278', 'grid_279', 'grid_364', 'grid_360', 'grid_361', 'grid_362', 'grid_363', 'grid_358', 'grid_359', 'grid_248', 'grid_249', 'grid_250', 'grid_332', 'grid_333', 'grid_334', 'grid_335', 'grid_330', 'grid_448', 'grid_220', 'grid_475', 'grid_221', 'grid_336', 'grid_219', 'grid_238', 'grid_239', 'grid_266', 'grid_267', 'grid_296', 'grid_184', 'grid_185', 'grid_186', 'grid_187', 'grid_294', 'grid_295', 'grid_183', 'grid_324', 'grid_212', 'grid_213', 'grid_214', 'grid_323', 'grid_210', 'grid_211', 'grid_240', 'grid_241', 'grid_242', 'grid_268', 'grid_128', 'grid_129', 'grid_130', 'grid_156', 'grid_127', 'grid_157', 'grid_158', 'grid_155', 'grid_160', 'grid_161', 'grid_159', 'grid_190', 'grid_191', 'grid_132', 'grid_133', 'grid_298', 'grid_328', 'grid_329', 'grid_326', 'grid_327', 'grid_356', 'grid_357', 'grid_354', 'grid_355', 'grid_384', 'grid_385', 'grid_383', 'grid_341', 'grid_342', 'grid_343', 'grid_338', 'grid_339', 'grid_40', 'grid_41', 'grid_292', 'grid_293', 'grid_39', 'grid_288', 'grid_289', 'grid_290', 'grid_291', 'grid_316', 'grid_317', 'grid_318', 'grid_319', 'grid_312', 'grid_313', 'grid_314', 'grid_315', 'grid_310', 'grid_311', 'grid_12', 'grid_13', 'grid_264', 'grid_265', 'grid_11', 'grid_260', 'grid_261', 'grid_262', 'grid_263', 'grid_258', 'grid_259', 'grid_284', 'grid_285', 'grid_286', 'grid_287', 'grid_236', 'grid_237', 'grid_232', 'grid_233', 'grid_234', 'grid_235', 'grid_204', 'grid_205', 'grid_206', 'grid_207', 'grid_208', 'grid_209', 'grid_429', 'grid_430', 'grid_180', 'grid_181', 'grid_182', 'grid_178', 'grid_179', 'grid_153', 'grid_154', 'grid_400', 'grid_401', 'grid_402', 'grid_403', 'grid_96', 'grid_97', 'grid_98', 'grid_124', 'grid_125', 'grid_126', 'grid_376', 'grid_372', 'grid_373', 'grid_374', 'grid_375', 'grid_370', 'grid_371', 'grid_68', 'grid_69', 'grid_320', 'grid_321', 'grid_67', 'grid_348', 'grid_95', 'grid_344', 'grid_345', 'grid_346', 'grid_347', 'grid_340', 'grid_297', 'grid_325', 'grid_269', 'grid_270', 'grid_440', 'grid_441', 'grid_442', 'grid_437', 'grid_580', 'grid_438', 'grid_581', 'grid_439', 'grid_496', 'grid_497', 'grid_498', 'grid_412', 'grid_413', 'grid_552', 'grid_409', 'grid_553', 'grid_410', 'grid_411', 'grid_468', 'grid_469', 'grid_470', 'grid_465', 'grid_608', 'grid_609', 'grid_466', 'grid_467', 'grid_381', 'grid_524', 'grid_525', 'grid_382', 'grid_162', 'grid_76', 'grid_77', 'grid_75', 'grid_104', 'grid_105', 'grid_106', 'grid_107', 'grid_103', 'grid_134', 'grid_135', 'grid_131', 'grid_36', 'grid_37', 'grid_38', 'grid_63', 'grid_9', 'grid_10', 'grid_256', 'grid_257', 'grid_281', 'grid_282', 'grid_283', 'grid_228', 'grid_229', 'grid_230', 'grid_231', 'grid_226', 'grid_227', 'grid_253', 'grid_254', 'grid_255', 'grid_200', 'grid_201', 'grid_202', 'grid_203', 'grid_199', 'grid_172', 'grid_173', 'grid_174', 'grid_175', 'grid_176', 'grid_177', 'grid_152', 'grid_148', 'grid_149', 'grid_150', 'grid_151', 'grid_145', 'grid_146', 'grid_147', 'grid_120', 'grid_121', 'grid_122', 'grid_123', 'grid_117', 'grid_118', 'grid_119', 'grid_64', 'grid_65', 'grid_66', 'grid_92', 'grid_93', 'grid_94', 'grid_90', 'grid_91', 'grid_436', 'grid_432', 'grid_433', 'grid_434', 'grid_435', 'grid_408', 'grid_404', 'grid_405', 'grid_406', 'grid_407', 'grid_489', 'grid_490', 'grid_491', 'grid_352', 'grid_353', 'grid_380', 'grid_377', 'grid_378', 'grid_379', 'grid_460', 'grid_461', 'grid_462', 'grid_463', 'grid_322', 'grid_349', 'grid_350', 'grid_351', 'grid_464']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_35560\\3244742007.py:4: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  df = pd.read_csv(\"dataset_4yr\\TPE_113_grid.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假設你的檔案叫 tpe_grids.csv\n",
    "df = pd.read_csv(\"dataset_4yr\\TPE_113_grid.csv\")\n",
    "\n",
    "# 取出所有 grid 欄位 (去掉 'index')\n",
    "grid_columns = [col for col in df.columns if col.startswith(\"grid_\")]\n",
    "print(grid_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eb35109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_id_to_index(grid_id, ncols=28):\n",
    "    # 假設 grid_id 是 0 開始編號的 28*28 flatten\n",
    "    row = grid_id // ncols\n",
    "    col = grid_id % ncols\n",
    "    return row, col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4613788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 建立一個 mask (28x28)\n",
    "mask = np.zeros((28, 28), dtype=bool)\n",
    "count = 0\n",
    "for col in grid_columns:\n",
    "    grid_id = int(col.replace(\"grid_\", \"\"))\n",
    "    grid_id = grid_id - 1  # 假設 grid_id 從 1 開始，轉換為 0 開始\n",
    "    row, col = grid_id_to_index(grid_id)\n",
    "    mask[col, row] = True\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d77c1a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\work\\DeepMeshCity\\testenv\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 21488 (\\N{CJK UNIFIED IDEOGRAPH-53F0}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\user\\Desktop\\work\\DeepMeshCity\\testenv\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 21271 (\\N{CJK UNIFIED IDEOGRAPH-5317}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\user\\Desktop\\work\\DeepMeshCity\\testenv\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 24066 (\\N{CJK UNIFIED IDEOGRAPH-5E02}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\user\\Desktop\\work\\DeepMeshCity\\testenv\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 26377 (\\N{CJK UNIFIED IDEOGRAPH-6709}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\user\\Desktop\\work\\DeepMeshCity\\testenv\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 25928 (\\N{CJK UNIFIED IDEOGRAPH-6548}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\user\\Desktop\\work\\DeepMeshCity\\testenv\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 32178 (\\N{CJK UNIFIED IDEOGRAPH-7DB2}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\user\\Desktop\\work\\DeepMeshCity\\testenv\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 26684 (\\N{CJK UNIFIED IDEOGRAPH-683C}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(mask, annot=True, fmt=\"d\", cmap=\"YlGnBu\", cbar=False, square=True)\n",
    "plt.title(\"台北市有效網格 Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ec5dc",
   "metadata": {},
   "source": [
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c559f474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os.path\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "\n",
    "def evaluate_model(model, MSE_criterion, DataLoader, device, configs, is_save, itr=999):\n",
    "    print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'test...')\n",
    "\n",
    "    res_path = os.path.join(configs.gen_frm_dir, str(itr))\n",
    "    if not os.path.exists(res_path):\n",
    "        os.mkdir(res_path)\n",
    "    avg_mse = 0\n",
    "    avg_rmse = 0\n",
    "    avg_mae = 0\n",
    "    correct_count = 0\n",
    "    item_count = 0\n",
    "    batch_id = 0\n",
    "\n",
    "    loss_list = []\n",
    "    model.eval()\n",
    "    all_tre = []\n",
    "    # only taipei\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch, item in enumerate(DataLoader):\n",
    "            print(\"batch\", batch)\n",
    "            batch_id = batch_id + 1\n",
    "            item_count = item_count+1\n",
    "            xc, xp, xt, ys, yd = item\n",
    "            xc, xp, xt, ys, yd = list(map(lambda x: x.to(device), [xc, xp, xt, ys, yd]))\n",
    "            pred = model(xc, xp, xt, yd)\n",
    "            # 準備 mask (B, 1, H, W)\n",
    "            B, C, H, W = ys.shape\n",
    "            valid_mask = torch.tensor(mask, dtype=ys.dtype, device=device).unsqueeze(0).unsqueeze(0)\n",
    "            valid_mask = valid_mask.expand(B, C, H, W)\n",
    "            valid_mask_np = valid_mask.cpu().numpy()\n",
    "            \n",
    "            print(\"valid_mask shape:\", valid_mask.shape)\n",
    "            pred = pred * valid_mask\n",
    "            ys = ys * valid_mask\n",
    "            print(\"pred shape:\", pred.shape, \"ys shape:\", ys.shape)\n",
    "            # # masked diff\n",
    "            # diff = (pred - ys) * valid_mask\n",
    "            # # loss\n",
    "            # mse = torch.mean(diff ** 2)\n",
    "            # mae = torch.mean(torch.abs(diff))\n",
    "            # rmse = torch.sqrt(torch.mean(diff ** 2))\n",
    "            \n",
    "            loss = MSE_criterion(pred, ys)\n",
    "            loss_item = loss.cpu().item()\n",
    "            loss_list.append(loss_item)\n",
    "            #print(\"validation:batch \",batch,\"loss=\",loss_item)\n",
    "            # MSE per frame\n",
    "            x = ys.cpu().numpy() * configs.max_value  # (B, H, W, C)\n",
    "            gx = pred.cpu().numpy() * configs.max_value\n",
    "            # gx[gx < 1] = 0\n",
    "            \n",
    "            mae = np.mean(np.abs(x - gx))\n",
    "            mse = np.mean(np.square(x - gx))\n",
    "            rmse = np.mean(np.square(x - gx))\n",
    "            \n",
    "            avg_mae += mae\n",
    "            avg_mse += mse\n",
    "            avg_rmse += rmse\n",
    "            \n",
    "            # TRE\n",
    "            \n",
    "            B = x.shape[0]  # 每個 batch 中有 B 筆資料\n",
    "            for i in range(B):\n",
    "                valid = valid_mask_np[i]\n",
    "                correct = np.sum((np.abs(x[i] - gx[i]) < 1) * valid)\n",
    "                tre = (1 - correct / count) * 100\n",
    "                all_tre.append(tre)\n",
    "                # draw \n",
    "                if TRE_draw == True:\n",
    "                    error = x[i] - gx[i]\n",
    "                    error = np.squeeze(x[i] - gx[i])\n",
    "                    \n",
    "                    fig = sns.heatmap(error, annot=True,annot_kws={\"size\": 3}, fmt=\".3f\", vmin=0, xticklabels=False,\n",
    "                        yticklabels=False, cbar=False, cmap='rainbow', square=True)\n",
    "                    heatmap = fig.get_figure()\n",
    "                    heatmap.savefig(os.path.join(\"error_map\", f\"error_map_{i}.png\"), dpi=300, bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "                    # debug\n",
    "                    fig = sns.heatmap(np.squeeze(x[i]), annot=True,annot_kws={\"size\": 3}, fmt=\".3f\", vmin=0, xticklabels=False,\n",
    "                        yticklabels=False, cbar=False, cmap='rainbow', square=True)\n",
    "                    heatmap = fig.get_figure()\n",
    "                    heatmap.savefig(os.path.join(\"error_map\", f\"true_{i}.png\"), dpi=300, bbox_inches='tight')\n",
    "                    plt.clf()\n",
    "            # save prediction examples\n",
    "            if batch_id <= configs.num_save_samples:\n",
    "                path = os.path.join(res_path, str(batch_id))\n",
    "                if not os.path.exists(path):\n",
    "                    os.mkdir(path)\n",
    "                for i in range(configs.input_length):\n",
    "                    name = 'gt' + str(i + 1) + '.png'\n",
    "                    file_name = os.path.join(path, name)\n",
    "                    img_c = xc[0, i, 0, :, :].cpu().numpy()\n",
    "                    draw_pic(img_c, file_name, configs.max_value)\n",
    "\n",
    "                name = 'pd7' + '.png'\n",
    "                file_name = os.path.join(path, name)\n",
    "                img_pd = pred[0, 0, :, :].cpu().numpy()\n",
    "                draw_pic(img_pd, file_name, configs.max_value)\n",
    "\n",
    "                name = 'gt7' + '.png'\n",
    "                file_name = os.path.join(path, name)\n",
    "                img_gt = ys[0, 0, :, :].cpu().numpy()\n",
    "                draw_pic(img_gt, file_name, configs.max_value)\n",
    "\n",
    "        avg_mse = avg_mse / batch_id\n",
    "        avg_mae = avg_mae / batch_id\n",
    "        avg_rmse = np.sqrt(avg_rmse / batch_id)\n",
    "        \n",
    "        # TRE\n",
    "        # total_pixels = x.size * batch_id\n",
    "        # tre = (1 - correct_count / total_pixels) * 100\n",
    "        sum_tre = np.sum(all_tre)\n",
    "        print(\"sum_tre:\", sum_tre)\n",
    "        print(\"count:\", count)\n",
    "        avg_tre = sum_tre / count\n",
    "        print('mse per frame: {}, rmse per frame: {}, mae per frame: {}, avg_tre : {} %'.format(avg_mse, avg_rmse, avg_mae,avg_tre))\n",
    "        if(is_save):\n",
    "            save_dir = \"report\"\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            now_str = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            log_path = os.path.join(save_dir, now_str + \".txt\")\n",
    "            with open(log_path, \"w\") as log_file:\n",
    "                log_file.write('mse per frame: {}, rmse per frame: {}, mae per frame: {}, avg_tre : {} %'.format(avg_mse, avg_rmse, avg_mae,avg_tre))\n",
    "        # save tre\n",
    "        with open(\"report/individual_tre.txt\", \"w\") as f:\n",
    "            for i, tre in enumerate(all_tre):\n",
    "                f.write(f\"Sample {i}: TRE = {tre:.2f}%\\n\")\n",
    "    return avg_mse, avg_rmse, avg_mae, tre\n",
    "\n",
    "\n",
    "def draw_pic(img_gt, file_name,denorm_factor=1.0 ):\n",
    "    img_gt[img_gt > 0.2] = 0.2\n",
    "    factor = 1.0 / 3.0\n",
    "    img_gt[(img_gt > 0.05) & (img_gt <= 0.2)] = img_gt[(img_gt > 0.05) & (img_gt <= 0.2)] * factor + 2 * factor * 0.05\n",
    "    img_gt = img_gt * denorm_factor\n",
    "    fig = sns.heatmap(img_gt, annot=True,annot_kws={\"size\": 3}, fmt=\".3f\", vmin=0, xticklabels=False,\n",
    "                      yticklabels=False, cbar=False, cmap='rainbow', square=True)\n",
    "    heatmap = fig.get_figure()\n",
    "    heatmap.savefig(file_name, dpi=300, bbox_inches='tight')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd882ab",
   "metadata": {},
   "source": [
    "# evaluate_model_with_custom_YD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79ca1235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_custom_YD(model, DataLoader, MSE_criterion, device, target_feature_idx, configs):\n",
    "    print(\"evaluate_model_with_custom_YD:\", target_feature_idx)\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_count = 0\n",
    "    batch_id = 0\n",
    "    avg_mse = 0\n",
    "    avg_rmse = 0\n",
    "    avg_mae = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, item in enumerate(DataLoader):\n",
    "            batch_id = batch_id + 1\n",
    "            xc, xp, xt, ys, yd = item\n",
    "            XC = xc.to(device)\n",
    "            XP = xp.to(device)\n",
    "            XT = xt.to(device)\n",
    "            YS = ys.to(device)\n",
    "            YD = yd.to(device)\n",
    "            print(\"YD shape:\", YD.shape)\n",
    "\n",
    "            YD_modified = YD.clone()\n",
    "            YD_modified[:, target_feature_idx] = 0  \n",
    "\n",
    "            pred = model(XC, XP, XT, YD_modified)\n",
    "            loss = MSE_criterion(pred, YS)\n",
    "            # MSE per frame\n",
    "            x = ys.cpu().numpy() * configs.max_value  # (B, H, W, C)\n",
    "            gx = pred.cpu().numpy() * configs.max_value\n",
    "            # gx[gx < 1] = 0\n",
    "            \n",
    "            mae = np.mean(np.abs(x - gx))\n",
    "            mse = np.mean(np.square(x - gx))\n",
    "            rmse = np.mean(np.square(x - gx))\n",
    "            \n",
    "            avg_mae += mae\n",
    "            avg_mse += mse\n",
    "            avg_rmse += rmse\n",
    "            # TRE\n",
    "            correct_count += np.sum(np.abs(x - gx) < 1)\n",
    "    avg_mse = avg_mse / batch_id\n",
    "    avg_mae = avg_mae / batch_id\n",
    "    avg_rmse = np.sqrt(avg_rmse / batch_id)\n",
    "\n",
    "    # TRE\n",
    "    total_pixels = x.size * batch_id\n",
    "    tre = (1 - correct_count / total_pixels) * 100\n",
    "    return avg_mse, avg_rmse, avg_mae, tre\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a87b2c0",
   "metadata": {},
   "source": [
    "# trainer_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99ec1542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, loss_func, dataloader, lr_scheduler, epoch, device):\n",
    "    loss_list = []\n",
    "    model.train()\n",
    "    print(\"The learning rate of the %dth epoch：%f\" % (epoch, optimizer.param_groups[0]['lr']))\n",
    "    for batch, item in tqdm(enumerate(dataloader)):\n",
    "        xc, xp, xt, ys, yd = item\n",
    "        xc, xp, xt, ys, yd = list(map(lambda x: Variable(x.to(device)), [xc, xp, xt, ys, yd]))\n",
    "        optimizer.zero_grad()\n",
    "        next_frame = model(xc, xp, xt, yd)\n",
    "        loss = loss_func(next_frame, ys)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_item = loss.cpu().item()\n",
    "        #print(\"train: batch \",batch,\"loss=\",loss_item)\n",
    "        loss_list.append(loss_item)\n",
    "\n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step(epoch)\n",
    "\n",
    "    return sum(loss_list) / len(loss_list)\n",
    "\n",
    "\n",
    "def test_epoch(model, loss_func, DataLoader, device):\n",
    "    loss_list = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, item in tqdm(enumerate(DataLoader)):\n",
    "            xc, xp, xt, ys, yd = item\n",
    "            xc, xp, xt, ys, yd = list(map(lambda x: x.to(device), [xc, xp, xt, ys, yd]))\n",
    "            next_frame = model(xc, xp, xt, yd)\n",
    "\n",
    "            loss = loss_func(next_frame, ys)\n",
    "            loss_list.append(loss.detach().cpu().item())\n",
    "\n",
    "    return sum(loss_list) / len(loss_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a43a8f7",
   "metadata": {},
   "source": [
    "# trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0d7fb989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_curves(train_loss_epoch, val_loss_epoch, tre_epoch, save_dir='loss_plots'):\n",
    "    \"\"\"\n",
    "    畫出訓練/驗證 loss 曲線與 tre_epoch 變化，並分別儲存圖片。\n",
    "    :param train_loss_epoch: List of training losses per epoch\n",
    "    :param val_loss_epoch: List of validation losses per epoch\n",
    "    :param tre_epoch: List of \"tre\" values per epoch\n",
    "    :param save_dir: Directory to save the plots\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.figure()\n",
    "    plt.plot(train_loss_epoch, label='Train Loss', color='blue')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss over Epochs')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'train_loss.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot validation loss\n",
    "    plt.figure()\n",
    "    plt.plot(val_loss_epoch, label='Validation Loss', color='green')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Validation Loss over Epochs')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'val_loss.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot TRE (or third metric)\n",
    "    plt.figure()\n",
    "    plt.plot(tre_epoch, label='TRE', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('TRE')\n",
    "    plt.title('TRE over Epochs')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'tre.png'))\n",
    "    plt.close()\n",
    "\n",
    "def  train_main(cfg, save = False):\n",
    "    # config\n",
    "    train_cfg = cfg.train_cfg\n",
    "    dataset_cfg = cfg.dataset_cfg\n",
    "    model_cfg = cfg.model_cfg\n",
    "    device = cfg.device\n",
    "\n",
    "    # dataset\n",
    "    train_dataset = Dataset_TPE(dataset_cfg, mode='train')\n",
    "    val_dataset = Dataset_TPE(dataset_cfg, mode='valid')\n",
    "    train_loader = DataLoader(train_dataset, batch_size=train_cfg.batch_size, shuffle=True, pin_memory=True,\n",
    "                              drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=train_cfg.batch_size, shuffle=False, pin_memory=True,\n",
    "                            drop_last=True)\n",
    "\n",
    "    print(train_cfg.optimizer_cfg)\n",
    "    # build model\n",
    "    model = build_model(model_cfg).to(device)\n",
    "\n",
    "    # whether Parallel\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "    if torch.cuda.device_count() == 1:\n",
    "        print(\"there is 1 GPU\")\n",
    "    parameters = model.parameters()\n",
    "\n",
    "    # Parameter information\n",
    "    print('Net\\'s state_dict:')\n",
    "    total_param = 0\n",
    "    for param_tensor in model.state_dict():\n",
    "        print(param_tensor, '\\t', model.state_dict()[param_tensor].size())\n",
    "        total_param += np.prod(model.state_dict()[param_tensor].size())\n",
    "    print('Net\\'s total params:', total_param)\n",
    "\n",
    "    # loss\n",
    "    MSE_criterion = nn.MSELoss().to(device)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer_cfg = train_cfg.optimizer_cfg\n",
    "    lr_scheduler_cfg = train_cfg.lr_scheduler_cfg\n",
    "    if optimizer_cfg.type == 'adam':\n",
    "        optimizer = optim.Adam(params=parameters,\n",
    "                               lr=optimizer_cfg.lr)\n",
    "    elif optimizer_cfg.type == 'adamw':\n",
    "        optimizer = optim.AdamW(params=parameters,\n",
    "                                lr=optimizer_cfg.lr,\n",
    "                                weight_decay=optimizer_cfg.weight_decay)\n",
    "    elif optimizer_cfg.type == 'sgd':\n",
    "        optimizer = optim.SGD(params=parameters,\n",
    "                              lr=optimizer_cfg.lr,\n",
    "                              momentum=optimizer_cfg.momentum,\n",
    "                              weight_decay=optimizer_cfg.weight_decay)\n",
    "    elif optimizer_cfg.type == 'RMS':\n",
    "        optimizer = optim.RMSprop(params=parameters,\n",
    "                                  lr=optimizer_cfg.lr,\n",
    "                                  momentum=optimizer_cfg.momentum,\n",
    "                                  weight_decay=optimizer_cfg.weight_decay)\n",
    "    else:\n",
    "        raise Exception('No Optimizer！')\n",
    "\n",
    "    # learning schedule\n",
    "    if lr_scheduler_cfg is None:\n",
    "        lr_scheduler = None\n",
    "    elif lr_scheduler_cfg.policy == 'step':\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, lr_scheduler_cfg.step_size,\n",
    "                                                       gamma=lr_scheduler_cfg.gamma, last_epoch=-1)\n",
    "    elif lr_scheduler_cfg.policy == 'cos':\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, lr_scheduler_cfg.T_0,\n",
    "                                                                            lr_scheduler_cfg.T_mult,\n",
    "                                                                            lr_scheduler_cfg.eta_min)\n",
    "    else:\n",
    "        lr_scheduler = None\n",
    "\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    Best_Metric = 0\n",
    "    Min_Metric = 999999999\n",
    "    best_epoch = 0\n",
    "    check_point_dir = '/'.join(train_cfg.check_point_file.split('/')[:-1])\n",
    "\n",
    "    if not os.path.exists(check_point_dir):\n",
    "        os.mkdir(check_point_dir)\n",
    "    train_loss_epoch = []\n",
    "    val_loss_epoch = []\n",
    "    tre_epoch = []\n",
    "    print(\"train_cfg.num_epochs = \", train_cfg.num_epochs)\n",
    "    for epoch in range(1, train_cfg.num_epochs + 1):\n",
    "        print()\n",
    "        print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "        start_time = time.time()\n",
    "        print(f\"It is the {epoch}th epoch...\")\n",
    "\n",
    "        # training\n",
    "        train_loss = train_epoch(model, optimizer, MSE_criterion, train_loader, lr_scheduler, epoch, device)\n",
    "        if epoch % train_cfg.test_interval == 0:\n",
    "            # validate\n",
    "            val_loss = evaluate_model(model, MSE_criterion, val_loader, device, train_cfg, False, epoch)\n",
    "            Best_Metric = val_loss[0]\n",
    "\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "        # save model\n",
    "        if Min_Metric > Best_Metric:\n",
    "            Min_Metric = Best_Metric\n",
    "            best_epoch = epoch\n",
    "            torch.save(model, train_cfg.check_point_file)\n",
    "\n",
    "        if epoch == 75 or epoch == 155 or epoch == train_cfg.num_epochs or save == True:\n",
    "            now = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            model_file = train_cfg.check_point_file.split('.')[0] + f'.pth'\n",
    "            torch.save(model, model_file)\n",
    "\n",
    "        # print out\n",
    "        test_end_time = time.time()\n",
    "        run_time = int(test_end_time - start_time)\n",
    "        m, s = divmod(run_time, 60)\n",
    "        time_str = \"{:02d}m{:02d}s\".format(m, s)\n",
    "        out_str = \"The {} epoch is finished, consuming {},\\n\" \\\n",
    "                  \"The loss on training set is {:.6f}；the best epoch is {}, best_metric={:.6f}\" \\\n",
    "            .format(epoch, time_str, sum(train_loss_list) / len(train_loss_list), best_epoch, Min_Metric)\n",
    "        print(out_str)\n",
    "        train_loss_epoch.append(sum(train_loss_list) / len(train_loss_list))\n",
    "        val_loss_epoch.append(Best_Metric)\n",
    "        tre_epoch.append(val_loss[3])\n",
    "    # draw train_loss_epoch & val_loss_epoch\n",
    "    plot_loss_curves(train_loss_epoch, val_loss_epoch, tre_epoch)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fb2252",
   "metadata": {},
   "source": [
    "# Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a03d9973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "\n",
    "def test_main(cfg):\n",
    "    # config\n",
    "    test_cfg = cfg.test_cfg\n",
    "    dataset_cfg = cfg.dataset_cfg\n",
    "    device = cfg.device\n",
    "    model_cfg = cfg.model_cfg\n",
    "\n",
    "    # dataset\n",
    "    test_dataset = Dataset_TPE(dataset_cfg, mode='test')\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_cfg.batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "    \n",
    "    # loss\n",
    "    model = build_model(model_cfg).to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    MSE_criterion = nn.MSELoss().to(device)\n",
    "    model_file = test_cfg.check_point_file\n",
    "    checkpoint = torch.load(model_file, map_location=device, weights_only=False)\n",
    "    model.load_state_dict(checkpoint.state_dict())\n",
    "    print(\"test_loader.dataset\",test_loader.dataset)\n",
    "    test_loss = evaluate_model(model, MSE_criterion, test_loader, device, test_cfg, False)\n",
    "    print('The loss on test set is {:.6f}'.format(test_loss[0]))\n",
    "\n",
    "    now_str = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"{now_str} test...\\n\")\n",
    "    \n",
    "    # ablation\n",
    "    \n",
    "    M = 14\n",
    "    importances = []\n",
    "    for i in range(7, M):\n",
    "        loss_i = evaluate_model_with_custom_YD(model, test_loader, MSE_criterion, device, i, test_cfg)\n",
    "        \n",
    "        importance = loss_i[0] - test_loss[0]\n",
    "        importances.append(importance)\n",
    "    print(importances)\n",
    "    # 畫出 bar chart\n",
    "    import matplotlib.pyplot as plt\n",
    "    feature_names = [\"workday\", \"rush hour\" ,\"weekend\" ,\"holiday\" ,\"make-up workday\" ,\"day of week\" ,\"weather\"]\n",
    "    plt.bar(range(7), importances)\n",
    "    plt.xticks(ticks=range(7), labels=feature_names, rotation=45, ha='right')\n",
    "    plt.xlabel(\"External Feature Index\")\n",
    "    plt.ylabel(\"Importance (Loss Increase)\")\n",
    "    plt.title(\"Feature Importance by Ablation\")\n",
    "    plt.savefig(\"feature_importance.png\", dpi=300, bbox_inches='tight')  # 存成 PNG\n",
    "    plt.close()\n",
    "    # # 假設 model 已經 load 完畢\n",
    "    # model_state = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()\n",
    "\n",
    "    # # 儲存資料夾\n",
    "    # save_dir = \"weights_txt\"\n",
    "    # os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # for name, param in model_state.items():\n",
    "    #     if 'weight' in name:\n",
    "    #         weight_np = param.detach().cpu().numpy()\n",
    "    #         save_path = os.path.join(save_dir, f\"{name.replace('.', '_')}.txt\")\n",
    "    #         np.savetxt(save_path, weight_np.flatten(), fmt=\"%.6f\")\n",
    "    #         print(f\"Saved {name} to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281f7625",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac4fc0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import sys\n",
    "from argparse import ArgumentParser\n",
    "from importlib import import_module\n",
    "\n",
    "from addict import Dict\n",
    "\n",
    "# from .misc import collections_abc\n",
    "\n",
    "\n",
    "class ConfigDict(Dict):\n",
    "    def __missing__(self, name):\n",
    "        raise KeyError(name)\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            value = super(ConfigDict, self).__getattr__(name)\n",
    "        except KeyError:\n",
    "            ex = AttributeError(\n",
    "                \"'{}' object has no attribute '{}'\".format(\n",
    "                    self.__class__.__name__, name\n",
    "                )\n",
    "            )\n",
    "        except Exception as e:\n",
    "            ex = e\n",
    "        else:\n",
    "            return value\n",
    "        raise ex\n",
    "\n",
    "\n",
    "def add_args(parser, cfg, prefix=\"\"):\n",
    "    for k, v in cfg.items():\n",
    "        if isinstance(v, str):\n",
    "            parser.add_argument(\"--\" + prefix + k)\n",
    "        elif isinstance(v, int):\n",
    "            parser.add_argument(\"--\" + prefix + k, type=int)\n",
    "        elif isinstance(v, float):\n",
    "            parser.add_argument(\"--\" + prefix + k, type=float)\n",
    "        elif isinstance(v, bool):\n",
    "            parser.add_argument(\"--\" + prefix + k, action=\"store_true\")\n",
    "        elif isinstance(v, dict):\n",
    "            add_args(parser, v, k + \".\")\n",
    "        # elif isinstance(v, collections_abc.Iterable):\n",
    "        #     parser.add_argument(\"--\" + prefix + k, type=type(v[0]), nargs=\"+\")\n",
    "        else:\n",
    "            print(\"connot parse key {} of type {}\".format(prefix + k, type(v)))\n",
    "    return parser\n",
    "\n",
    "\n",
    "class Config(object):\n",
    "    \"\"\"A facility for config and config files.\n",
    "    It supports common file formats as configs: python/json/yaml. The interface\n",
    "    is the same as a dict object and also allows access config values as\n",
    "    attributes.\n",
    "    Example:\n",
    "        >>> cfg = Config(dict(a=1, b=dict(b1=[0, 1])))\n",
    "        >>> cfg.a\n",
    "        1\n",
    "        >>> cfg.b\n",
    "        {'b1': [0, 1]}\n",
    "        >>> cfg.b.b1\n",
    "        [0, 1]\n",
    "        >>> cfg = Config.fromfile('tests/data/config/a.py')\n",
    "        >>> cfg.filename\n",
    "        \"/home/kchen/projects/torchie/tests/data/config/a.py\"\n",
    "        >>> cfg.item4\n",
    "        'test'\n",
    "        >>> cfg\n",
    "        \"Config [path: /home/kchen/projects/torchie/tests/data/config/a.py]: \"\n",
    "        \"{'item1': [1, 2], 'item2': {'a': 0}, 'item3': True, 'item4': 'test'}\"\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def fromfile(filename):\n",
    "        filename = osp.abspath(osp.expanduser(filename))\n",
    "        if not osp.isfile(filename):\n",
    "            raise FileNotFoundError('file \"{}\" does not exist'.format(filename))\n",
    "\n",
    "        if filename.endswith(\".py\"):\n",
    "            module_name = osp.basename(filename)[:-3]\n",
    "            if \".\" in module_name:\n",
    "                raise ValueError(\"Dots are not allowed in config file path.\")\n",
    "            config_dir = osp.dirname(filename)\n",
    "            sys.path.insert(0, config_dir)\n",
    "            mod = import_module(module_name)\n",
    "            sys.path.pop(0)\n",
    "            cfg_dict = {\n",
    "                name: value\n",
    "                for name, value in mod.__dict__.items()\n",
    "                if not name.startswith(\"__\")\n",
    "            }\n",
    "        elif filename.endswith((\".yml\", \".yaml\", \".json\")):\n",
    "            import torchie\n",
    "\n",
    "            cfg_dict = torchie.load(filename)\n",
    "        else:\n",
    "            raise IOError(\"Only py/yml/yaml/json type are supported now!\")\n",
    "        return Config(cfg_dict, filename=filename)\n",
    "\n",
    "    @staticmethod\n",
    "    def auto_argparser(description=None):\n",
    "        \"\"\"Generate argparser from config file automatically (experimental)\n",
    "        \"\"\"\n",
    "        partial_parser = ArgumentParser(description=description)\n",
    "        partial_parser.add_argument(\"config\", help=\"config file path\")\n",
    "        cfg_file = partial_parser.parse_known_args()[0].config\n",
    "        cfg = Config.fromfile(cfg_file)\n",
    "        parser = ArgumentParser(description=description)\n",
    "        parser.add_argument(\"config\", help=\"config file path\")\n",
    "        add_args(parser, cfg)\n",
    "        return parser, cfg\n",
    "\n",
    "    def __init__(self, cfg_dict=None, filename=None):\n",
    "        if cfg_dict is None:\n",
    "            cfg_dict = dict()\n",
    "        elif not isinstance(cfg_dict, dict):\n",
    "            raise TypeError(\n",
    "                \"cfg_dict must be a dict, but got {}\".format(type(cfg_dict))\n",
    "            )\n",
    "\n",
    "        super(Config, self).__setattr__(\"_cfg_dict\", ConfigDict(cfg_dict))\n",
    "        super(Config, self).__setattr__(\"_filename\", filename)\n",
    "        if filename:\n",
    "            with open(filename, \"r\") as f:\n",
    "                super(Config, self).__setattr__(\"_text\", f.read())\n",
    "        else:\n",
    "            super(Config, self).__setattr__(\"_text\", \"\")\n",
    "\n",
    "    @property\n",
    "    def filename(self):\n",
    "        return self._filename\n",
    "\n",
    "    @property\n",
    "    def text(self):\n",
    "        return self._text\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Config (path: {}): {}\".format(self.filename, self._cfg_dict.__repr__())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._cfg_dict)\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._cfg_dict, name)\n",
    "\n",
    "    def __getitem__(self, name):\n",
    "        return self._cfg_dict.__getitem__(name)\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if isinstance(value, dict):\n",
    "            value = ConfigDict(value)\n",
    "        self._cfg_dict.__setattr__(name, value)\n",
    "\n",
    "    def __setitem__(self, name, value):\n",
    "        if isinstance(value, dict):\n",
    "            value = ConfigDict(value)\n",
    "        self._cfg_dict.__setitem__(name, value)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self._cfg_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee12c91",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "477bfd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config filename: DeepMeshCity_TPE_flow_config.py\n",
      "random seed is 6666\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "cfg_filename = \"DeepMeshCity_TPE_flow_config.py\"  # config filename\n",
    "data = \"TPE\"\n",
    "task = \"flow\"  # flow,density\n",
    "\n",
    "# read config\n",
    "cfg = Config.fromfile('./Config/' + data + '/' + task + '/' + cfg_filename)\n",
    "print(\"config filename: \" + str(cfg_filename))\n",
    "\n",
    "set_seed(cfg.random_seed)\n",
    "print(\"random seed is {}\".format(cfg.random_seed))\n",
    "\n",
    "split_save_dir = cfg.train_cfg.check_point_file.split('/')\n",
    "save_dir = os.path.join(split_save_dir[0], os.path.join(split_save_dir[1], split_save_dir[2]))\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "if not os.path.exists(cfg.train_cfg.gen_frm_dir):\n",
    "    os.makedirs(cfg.train_cfg.gen_frm_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce174542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'input_length': 6,\n",
       " 'num_epochs': 5,\n",
       " 'max_value': 32,\n",
       " 'test_interval': 1,\n",
       " 'num_save_samples': 3,\n",
       " 'optimizer_cfg': {'type': 'adamw', 'lr': 0.001, 'weight_decay': 0.0005},\n",
       " 'lr_scheduler_cfg': {'policy': 'cos',\n",
       "  'T_0': 5,\n",
       "  'T_mult': 2,\n",
       "  'eta_min': 1e-05},\n",
       " 'check_point_file': 'checkpoint/TPE/flow/DeepMeshCity.pth',\n",
       " 'gen_frm_dir': 'Results/TPE/flow/DeepMeshCity_07_04'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.train_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00cbcc",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "565b9f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7377, 6, 1, 28, 28) (7377, 1, 1, 28, 28) (7377, 1, 1, 28, 28) (7377, 1, 28, 28) (7377, 32) 32\n",
      "(1053, 6, 1, 28, 28) (1053, 1, 1, 28, 28) (1053, 1, 1, 28, 28) (1053, 1, 28, 28) (1053, 32) 32\n",
      "{'type': 'adamw', 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "there is 1 GPU\n",
      "Net's state_dict:\n",
      "meta_learn.0.weight \t torch.Size([10, 32])\n",
      "meta_learn.0.bias \t torch.Size([10])\n",
      "meta_learn.2.weight \t torch.Size([784, 10])\n",
      "meta_learn.2.bias \t torch.Size([784])\n",
      "SACGL_blocks.0.0.layer_q.weight \t torch.Size([64, 32, 1, 1])\n",
      "SACGL_blocks.0.0.layer_q.bias \t torch.Size([64])\n",
      "SACGL_blocks.0.0.layer_k.weight \t torch.Size([64, 32, 1, 1])\n",
      "SACGL_blocks.0.0.layer_k.bias \t torch.Size([64])\n",
      "SACGL_blocks.0.0.layer_v.weight \t torch.Size([64, 32, 1, 1])\n",
      "SACGL_blocks.0.0.layer_v.bias \t torch.Size([64])\n",
      "SACGL_blocks.0.0.layer_f.weight \t torch.Size([32, 64, 1, 1])\n",
      "SACGL_blocks.0.0.layer_f.bias \t torch.Size([32])\n",
      "SACGL_blocks.0.1.conv_x.0.weight \t torch.Size([256, 2, 3, 3])\n",
      "SACGL_blocks.0.1.conv_x.0.bias \t torch.Size([256])\n",
      "SACGL_blocks.0.1.conv_x.1.weight \t torch.Size([256])\n",
      "SACGL_blocks.0.1.conv_x.1.bias \t torch.Size([256])\n",
      "SACGL_blocks.0.1.conv_c.0.weight \t torch.Size([128, 64, 3, 3])\n",
      "SACGL_blocks.0.1.conv_c.0.bias \t torch.Size([128])\n",
      "SACGL_blocks.0.1.conv_c.1.weight \t torch.Size([128])\n",
      "SACGL_blocks.0.1.conv_c.1.bias \t torch.Size([128])\n",
      "SACGL_blocks.0.1.conv_m.0.weight \t torch.Size([128, 64, 3, 3])\n",
      "SACGL_blocks.0.1.conv_m.0.bias \t torch.Size([128])\n",
      "SACGL_blocks.0.1.conv_m.1.weight \t torch.Size([128])\n",
      "SACGL_blocks.0.1.conv_m.1.bias \t torch.Size([128])\n",
      "SACGL_blocks.0.1.conv_o_c.0.weight \t torch.Size([64, 128, 1, 1])\n",
      "SACGL_blocks.0.1.conv_o_c.0.bias \t torch.Size([64])\n",
      "SACGL_blocks.0.1.conv_o_c.1.weight \t torch.Size([64])\n",
      "SACGL_blocks.0.1.conv_o_c.1.bias \t torch.Size([64])\n",
      "SACGL_blocks.0.1.conv_last.weight \t torch.Size([64, 128, 1, 1])\n",
      "SACGL_blocks.0.1.conv_last.bias \t torch.Size([64])\n",
      "SACGL_blocks.1.0.layer_q.weight \t torch.Size([64, 1024, 1, 1])\n",
      "SACGL_blocks.1.0.layer_q.bias \t torch.Size([64])\n",
      "SACGL_blocks.1.0.layer_k.weight \t torch.Size([64, 1024, 1, 1])\n",
      "SACGL_blocks.1.0.layer_k.bias \t torch.Size([64])\n",
      "SACGL_blocks.1.0.layer_v.weight \t torch.Size([64, 1024, 1, 1])\n",
      "SACGL_blocks.1.0.layer_v.bias \t torch.Size([64])\n",
      "SACGL_blocks.1.0.layer_f.weight \t torch.Size([1024, 64, 1, 1])\n",
      "SACGL_blocks.1.0.layer_f.bias \t torch.Size([1024])\n",
      "SACGL_blocks.1.1.conv_x.0.weight \t torch.Size([256, 64, 3, 3])\n",
      "SACGL_blocks.1.1.conv_x.0.bias \t torch.Size([256])\n",
      "SACGL_blocks.1.1.conv_x.1.weight \t torch.Size([256])\n",
      "SACGL_blocks.1.1.conv_x.1.bias \t torch.Size([256])\n",
      "SACGL_blocks.1.1.conv_c.0.weight \t torch.Size([128, 64, 3, 3])\n",
      "SACGL_blocks.1.1.conv_c.0.bias \t torch.Size([128])\n",
      "SACGL_blocks.1.1.conv_c.1.weight \t torch.Size([128])\n",
      "SACGL_blocks.1.1.conv_c.1.bias \t torch.Size([128])\n",
      "SACGL_blocks.1.1.conv_m.0.weight \t torch.Size([128, 64, 3, 3])\n",
      "SACGL_blocks.1.1.conv_m.0.bias \t torch.Size([128])\n",
      "SACGL_blocks.1.1.conv_m.1.weight \t torch.Size([128])\n",
      "SACGL_blocks.1.1.conv_m.1.bias \t torch.Size([128])\n",
      "SACGL_blocks.1.1.conv_o_c.0.weight \t torch.Size([64, 128, 1, 1])\n",
      "SACGL_blocks.1.1.conv_o_c.0.bias \t torch.Size([64])\n",
      "SACGL_blocks.1.1.conv_o_c.1.weight \t torch.Size([64])\n",
      "SACGL_blocks.1.1.conv_o_c.1.bias \t torch.Size([64])\n",
      "SACGL_blocks.1.1.conv_last.weight \t torch.Size([64, 128, 1, 1])\n",
      "SACGL_blocks.1.1.conv_last.bias \t torch.Size([64])\n",
      "Output_module.0.weight \t torch.Size([64, 64, 1, 1])\n",
      "Output_module.2.weight \t torch.Size([1, 64, 1, 1])\n",
      "Net's total params: 768218\n",
      "train_cfg.num_epochs =  5\n",
      "\n",
      "2025-07-04 01:56:09\n",
      "It is the 1th epoch...\n",
      "The learning rate of the 1th epoch：0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [00:18, 12.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-04 01:56:27 test...\n",
      "batch 0\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 1\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 2\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 3\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 4\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 5\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 6\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 7\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 8\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 9\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 10\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 11\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 12\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 13\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 14\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 15\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 16\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 17\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 18\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 19\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 20\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 21\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 22\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 23\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 24\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 25\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 26\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 27\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 28\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 29\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 30\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 31\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "sum_tre: 3670.3594\n",
      "count: 334\n",
      "mse per frame: 0.08694309741258621, rmse per frame: 0.2948611378669739, mae per frame: 0.08985370397567749, avg_tre : 10.989099502563477 %\n",
      "The 1 epoch is finished, consuming 00m27s,\n",
      "The loss on training set is 0.000115；the best epoch is 1, best_metric=0.086943\n",
      "\n",
      "2025-07-04 01:56:37\n",
      "It is the 2th epoch...\n",
      "The learning rate of the 2th epoch：0.000905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [00:17, 12.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-04 01:56:54 test...\n",
      "batch 0\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 1\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 2\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 3\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 4\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 5\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 6\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 7\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 8\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 9\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 10\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 11\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 12\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 13\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 14\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 15\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 16\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 17\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 18\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 19\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 20\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 21\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 22\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 23\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 24\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 25\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 26\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 27\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 28\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 29\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 30\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 31\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "sum_tre: 3772.1555\n",
      "count: 334\n",
      "mse per frame: 0.08628758043050766, rmse per frame: 0.2937474846839905, mae per frame: 0.0872393324971199, avg_tre : 11.293878555297852 %\n",
      "The 2 epoch is finished, consuming 00m26s,\n",
      "The loss on training set is 0.000096；the best epoch is 2, best_metric=0.086288\n",
      "\n",
      "2025-07-04 01:57:04\n",
      "It is the 3th epoch...\n",
      "The learning rate of the 3th epoch：0.000658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [00:17, 12.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-04 01:57:21 test...\n",
      "batch 0\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 1\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 2\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 3\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 4\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 5\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 6\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 7\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 8\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 9\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 10\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 11\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 12\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 13\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 14\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 15\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 16\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 17\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 18\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 19\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 20\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 21\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 22\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 23\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 24\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 25\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 26\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 27\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 28\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 29\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 30\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 31\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "sum_tre: 3879.042\n",
      "count: 334\n",
      "mse per frame: 0.0856587141752243, rmse per frame: 0.29267510771751404, mae per frame: 0.08705305308103561, avg_tre : 11.613898277282715 %\n",
      "The 3 epoch is finished, consuming 00m27s,\n",
      "The loss on training set is 0.000090；the best epoch is 3, best_metric=0.085659\n",
      "\n",
      "2025-07-04 01:57:31\n",
      "It is the 4th epoch...\n",
      "The learning rate of the 4th epoch：0.000352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [00:17, 13.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-04 01:57:48 test...\n",
      "batch 0\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 1\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 2\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 3\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 4\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 5\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 6\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 7\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 8\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 9\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 10\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 11\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 12\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 13\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 14\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 15\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 16\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 17\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 18\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 19\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 20\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 21\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 22\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 23\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 24\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 25\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 26\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 27\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 28\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 29\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 30\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 31\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "sum_tre: 3785.629\n",
      "count: 334\n",
      "mse per frame: 0.08539120852947235, rmse per frame: 0.2922177314758301, mae per frame: 0.08647427707910538, avg_tre : 11.33421802520752 %\n",
      "The 4 epoch is finished, consuming 00m26s,\n",
      "The loss on training set is 0.000087；the best epoch is 4, best_metric=0.085391\n",
      "\n",
      "2025-07-04 01:57:58\n",
      "It is the 5th epoch...\n",
      "The learning rate of the 5th epoch：0.000105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [00:17, 12.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-04 01:58:15 test...\n",
      "batch 0\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 1\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 2\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 3\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 4\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 5\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 6\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 7\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 8\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 9\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 10\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 11\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 12\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 13\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 14\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 15\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 16\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 17\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 18\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 19\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 20\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 21\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 22\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 23\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 24\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 25\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 26\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 27\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 28\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 29\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 30\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 31\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "sum_tre: 3713.7725\n",
      "count: 334\n",
      "mse per frame: 0.08525615930557251, rmse per frame: 0.2919865846633911, mae per frame: 0.08641503751277924, avg_tre : 11.11907958984375 %\n",
      "The 5 epoch is finished, consuming 00m26s,\n",
      "The loss on training set is 0.000085；the best epoch is 5, best_metric=0.085256\n"
     ]
    }
   ],
   "source": [
    "mode = \"train\"  # train, test, ablation\n",
    "TRE_draw = False\n",
    "train_main(cfg, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb42b63",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b340d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1719, 6, 1, 28, 28) (1719, 1, 1, 28, 28) (1719, 1, 1, 28, 28) (1719, 1, 28, 28) (1719, 13) 1292.0\n",
      "checkpoint/TPE/flow/DeepMeshCity.pth\n",
      "2025-05-16 01:27:03 test...\n",
      "mse per frame: 144.23587036132812, rmse per frame: 12.0098237991333, mae per frame: 3.602595090866089, tre : 27.40910485656527 %\n",
      "The loss on test set is 144.235870\n",
      "2025-05-16 01:27:32 test...\n",
      "Saved meta_learn.0.weight to weights_txt\\meta_learn_0_weight.txt\n",
      "Saved meta_learn.2.weight to weights_txt\\meta_learn_2_weight.txt\n",
      "Saved SACGL_blocks.0.0.layer_q.weight to weights_txt\\SACGL_blocks_0_0_layer_q_weight.txt\n",
      "Saved SACGL_blocks.0.0.layer_k.weight to weights_txt\\SACGL_blocks_0_0_layer_k_weight.txt\n",
      "Saved SACGL_blocks.0.0.layer_v.weight to weights_txt\\SACGL_blocks_0_0_layer_v_weight.txt\n",
      "Saved SACGL_blocks.0.0.layer_f.weight to weights_txt\\SACGL_blocks_0_0_layer_f_weight.txt\n",
      "Saved SACGL_blocks.0.1.conv_x.0.weight to weights_txt\\SACGL_blocks_0_1_conv_x_0_weight.txt\n",
      "Saved SACGL_blocks.0.1.conv_x.1.weight to weights_txt\\SACGL_blocks_0_1_conv_x_1_weight.txt\n",
      "Saved SACGL_blocks.0.1.conv_c.0.weight to weights_txt\\SACGL_blocks_0_1_conv_c_0_weight.txt\n",
      "Saved SACGL_blocks.0.1.conv_c.1.weight to weights_txt\\SACGL_blocks_0_1_conv_c_1_weight.txt\n",
      "Saved SACGL_blocks.0.1.conv_m.0.weight to weights_txt\\SACGL_blocks_0_1_conv_m_0_weight.txt\n",
      "Saved SACGL_blocks.0.1.conv_m.1.weight to weights_txt\\SACGL_blocks_0_1_conv_m_1_weight.txt\n",
      "Saved SACGL_blocks.0.1.conv_o_c.0.weight to weights_txt\\SACGL_blocks_0_1_conv_o_c_0_weight.txt\n",
      "Saved SACGL_blocks.0.1.conv_o_c.1.weight to weights_txt\\SACGL_blocks_0_1_conv_o_c_1_weight.txt\n",
      "Saved SACGL_blocks.0.1.conv_last.weight to weights_txt\\SACGL_blocks_0_1_conv_last_weight.txt\n",
      "Saved SACGL_blocks.1.0.layer_q.weight to weights_txt\\SACGL_blocks_1_0_layer_q_weight.txt\n",
      "Saved SACGL_blocks.1.0.layer_k.weight to weights_txt\\SACGL_blocks_1_0_layer_k_weight.txt\n",
      "Saved SACGL_blocks.1.0.layer_v.weight to weights_txt\\SACGL_blocks_1_0_layer_v_weight.txt\n",
      "Saved SACGL_blocks.1.0.layer_f.weight to weights_txt\\SACGL_blocks_1_0_layer_f_weight.txt\n",
      "Saved SACGL_blocks.1.1.conv_x.0.weight to weights_txt\\SACGL_blocks_1_1_conv_x_0_weight.txt\n",
      "Saved SACGL_blocks.1.1.conv_x.1.weight to weights_txt\\SACGL_blocks_1_1_conv_x_1_weight.txt\n",
      "Saved SACGL_blocks.1.1.conv_c.0.weight to weights_txt\\SACGL_blocks_1_1_conv_c_0_weight.txt\n",
      "Saved SACGL_blocks.1.1.conv_c.1.weight to weights_txt\\SACGL_blocks_1_1_conv_c_1_weight.txt\n",
      "Saved SACGL_blocks.1.1.conv_m.0.weight to weights_txt\\SACGL_blocks_1_1_conv_m_0_weight.txt\n",
      "Saved SACGL_blocks.1.1.conv_m.1.weight to weights_txt\\SACGL_blocks_1_1_conv_m_1_weight.txt\n",
      "Saved SACGL_blocks.1.1.conv_o_c.0.weight to weights_txt\\SACGL_blocks_1_1_conv_o_c_0_weight.txt\n",
      "Saved SACGL_blocks.1.1.conv_o_c.1.weight to weights_txt\\SACGL_blocks_1_1_conv_o_c_1_weight.txt\n",
      "Saved SACGL_blocks.1.1.conv_last.weight to weights_txt\\SACGL_blocks_1_1_conv_last_weight.txt\n",
      "Saved Output_module.0.weight to weights_txt\\Output_module_0_weight.txt\n",
      "Saved Output_module.2.weight to weights_txt\\Output_module_2_weight.txt\n"
     ]
    }
   ],
   "source": [
    "test_main(cfg=cfg) # no external 75 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d657da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 6, 1, 28, 28) (168, 1, 1, 28, 28) (168, 1, 1, 28, 28) (168, 1, 28, 28) (168, 14) 1292.0\n",
      "2025-06-06 01:41:31 test...\n",
      "The loss on test set is 147.436371\n",
      "2025-06-06 01:41:46 test...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_main(cfg=cfg) # with external 10 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee5c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 6, 1, 28, 28) (168, 1, 1, 28, 28) (168, 1, 1, 28, 28) (168, 1, 28, 28) (168, 14) 1292.0\n",
      "2025-06-06 09:38:21 test...\n",
      "The loss on test set is 229.011154\n",
      "2025-06-06 09:38:34 test...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_main(cfg=cfg) # with external 150 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437afe1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 6, 1, 28, 28) (168, 1, 1, 28, 28) (168, 1, 1, 28, 28) (168, 1, 28, 28) (168, 14) 1292.0\n",
      "2025-06-06 10:09:53 test...\n",
      "The loss on test set is 229.011154\n",
      "2025-06-06 10:10:07 test...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_main(cfg=cfg) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f00737f",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f985d356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 6, 1, 28, 28) (168, 1, 1, 28, 28) (168, 1, 1, 28, 28) (168, 1, 28, 28) (168, 32) 32\n",
      "test_loader.dataset <__main__.Dataset_TPE object at 0x00000167FC5B1590>\n",
      "2025-07-04 02:12:09 test...\n",
      "batch 0\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 1\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 2\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 3\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "batch 4\n",
      "valid_mask shape: torch.Size([32, 1, 28, 28])\n",
      "pred shape: torch.Size([32, 1, 28, 28]) ys shape: torch.Size([32, 1, 28, 28])\n",
      "sum_tre: 623.6527\n",
      "count: 334\n",
      "mse per frame: 0.08946798741817474, rmse per frame: 0.2991119921207428, mae per frame: 0.0890723317861557, avg_tre : 1.8672237396240234 %\n",
      "The loss on test set is 0.089468\n",
      "2025-07-04 02:14:12 test...\n",
      "\n",
      "evaluate_model_with_custom_YD: 7\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "evaluate_model_with_custom_YD: 8\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "evaluate_model_with_custom_YD: 9\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "evaluate_model_with_custom_YD: 10\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "evaluate_model_with_custom_YD: 11\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "evaluate_model_with_custom_YD: 12\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "evaluate_model_with_custom_YD: 13\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "[np.float32(0.00031668693), np.float32(0.00076051056), np.float32(0.00015473366), np.float32(6.559491e-05), np.float32(6.559491e-05), np.float32(0.001955174), np.float32(0.04639317)]\n"
     ]
    }
   ],
   "source": [
    "TRE_draw = True\n",
    "test_main(cfg=cfg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44d5d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
