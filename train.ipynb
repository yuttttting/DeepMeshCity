{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c64ea29",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16f941ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class Dataset_TPE(Dataset):\n",
    "    def __init__(self, configs, mode):\n",
    "        self.datapath = configs.datapath\n",
    "        self.data_type = configs.data_type\n",
    "        self.max_value = configs.max_value\n",
    "        if mode == 'train':\n",
    "            self.name = 'train_' + self.data_type + '.npz'\n",
    "        elif mode == 'valid':\n",
    "            self.name = 'valid_' + self.data_type + '.npz'\n",
    "        else:\n",
    "            self.name = 'test_' + self.data_type + '.npz'\n",
    "        path = os.path.join(self.datapath, self.name)\n",
    "        self.data = self.load_data(path)\n",
    "\n",
    "    def load_data(self, path):\n",
    "        all_data = np.load(path)\n",
    "        self.XC = all_data['xc']\n",
    "        self.XP = all_data['xp']\n",
    "        self.XT = all_data['xt']\n",
    "        self.YS = all_data['ys']\n",
    "        self.YD = all_data['yd']\n",
    "\n",
    "        print(self.XC.shape, self.XP.shape, self.XT.shape, self.YS.shape, self.YD.shape, self.max_value)\n",
    "\n",
    "        return all_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data['xc'].shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        XC = torch.FloatTensor(self.XC[item])\n",
    "        XP = torch.FloatTensor(self.XP[item])\n",
    "        XT = torch.FloatTensor(self.XT[item])\n",
    "        YS = torch.FloatTensor(self.YS[item])\n",
    "        YD = torch.FloatTensor(self.YD[item])\n",
    "\n",
    "        return XC, XP, XT, YS, YD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee745b86",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7d0e5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CGL(nn.Module):\n",
    "    def __init__(self, in_channel, num_hidden, filter_size, stride, is_norm):\n",
    "        super(CGL, self).__init__()\n",
    "\n",
    "        self.num_hidden = num_hidden\n",
    "        self.padding = filter_size // 2\n",
    "        self.forget_bias = -1.0\n",
    "\n",
    "        if is_norm:\n",
    "            self.conv_x = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, num_hidden * 4, kernel_size=filter_size, stride=stride, padding=self.padding),\n",
    "                nn.GroupNorm(num_hidden // 2, 4 * num_hidden)\n",
    "            )\n",
    "            self.conv_c = nn.Sequential(\n",
    "                nn.Conv2d(num_hidden, num_hidden * 2, kernel_size=filter_size, stride=stride, padding=self.padding),\n",
    "                nn.GroupNorm(num_hidden // 2, num_hidden * 2)\n",
    "            )\n",
    "\n",
    "            self.conv_m = nn.Sequential(\n",
    "                nn.Conv2d(num_hidden, num_hidden * 2, kernel_size=filter_size, stride=stride, padding=self.padding),\n",
    "                nn.GroupNorm(num_hidden // 2, num_hidden * 2)\n",
    "            )\n",
    "            self.conv_o_c = nn.Sequential(\n",
    "                nn.Conv2d(num_hidden * 2, num_hidden, kernel_size=1, stride=1, padding=0),\n",
    "                nn.GroupNorm(num_hidden // 2, num_hidden)\n",
    "            )\n",
    "        else:\n",
    "            self.conv_x = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, num_hidden * 4, kernel_size=filter_size, stride=stride, padding=self.padding),\n",
    "            )\n",
    "            self.conv_c = nn.Sequential(\n",
    "                nn.Conv2d(num_hidden, num_hidden * 2, kernel_size=filter_size, stride=stride, padding=self.padding),\n",
    "            )\n",
    "            self.conv_m = nn.Sequential(\n",
    "                nn.Conv2d(num_hidden, num_hidden * 2, kernel_size=filter_size, stride=stride, padding=self.padding),\n",
    "            )\n",
    "            self.conv_o_c = nn.Sequential(\n",
    "                nn.Conv2d(num_hidden * 2, num_hidden, kernel_size=filter_size, stride=stride, padding=self.padding),\n",
    "            )\n",
    "\n",
    "        self.conv_last = nn.Conv2d(num_hidden * 2, num_hidden, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x_t, c_t, m_t):\n",
    "        x_concat = self.conv_x(x_t)\n",
    "        m_concat = self.conv_m(m_t)\n",
    "        c_concat = self.conv_c(c_t)\n",
    "\n",
    "        x_p, f_x, x_m_p, f_m_x = torch.split(x_concat, self.num_hidden, dim=1)\n",
    "        f_m, g_m = torch.split(m_concat, self.num_hidden, dim=1)\n",
    "        f_c, g_c = torch.split(c_concat, self.num_hidden, dim=1)\n",
    "\n",
    "        f_t = torch.sigmoid(f_x + f_c + self.forget_bias)\n",
    "        x_p_t = torch.tanh(x_p + g_c)\n",
    "\n",
    "        c = f_t * c_t + (1 - f_t) * x_p_t\n",
    "\n",
    "        f_t_prime = torch.sigmoid(f_m_x + f_m + self.forget_bias)\n",
    "        g_t_prime = torch.tanh(x_m_p + g_m)\n",
    "\n",
    "        m = f_t_prime * m_t + (1 - f_t_prime) * g_t_prime\n",
    "\n",
    "        mem = torch.cat((c, m), 1)\n",
    "\n",
    "        o_t = torch.sigmoid(self.conv_o_c(mem))\n",
    "        h_new = o_t * torch.tanh(self.conv_last(mem))\n",
    "\n",
    "        return h_new, c, m\n",
    "\n",
    "\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_szie=1):\n",
    "        super(self_attention, self).__init__()\n",
    "        self.layer_q = nn.Conv2d(input_dim, hidden_dim, kernel_szie)\n",
    "        self.layer_k = nn.Conv2d(input_dim, hidden_dim, kernel_szie)\n",
    "        self.layer_v = nn.Conv2d(input_dim, hidden_dim, kernel_szie)\n",
    "        self.layer_f = nn.Conv2d(hidden_dim, input_dim, kernel_szie)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def forward(self, q, k, v, extra=None):\n",
    "        batch_size, channel, H, W = q.shape\n",
    "        h = q  # short connection\n",
    "\n",
    "        q = self.layer_q(q)\n",
    "        k = self.layer_k(k)\n",
    "        v = self.layer_v(v)\n",
    "\n",
    "        if extra is not None:\n",
    "            # 外部特徵 encode 成 attention bias\n",
    "            # extra shape: (B, M, H, W)\n",
    "            extra_flat = extra.view(batch_size, -1, H * W)\n",
    "            q = q + extra_flat.mean(dim=1, keepdim=True).unsqueeze(-1)  # broadcast to q shape\n",
    "            k = k + extra_flat.mean(dim=1, keepdim=True).unsqueeze(-1)\n",
    "\n",
    "        q = q.view(batch_size, self.hidden_dim, H * W)\n",
    "        k = k.view(batch_size, self.hidden_dim, H * W)\n",
    "        v = v.view(batch_size, self.hidden_dim, H * W)\n",
    "\n",
    "        attn = torch.matmul(q.transpose(1, 2), k)\n",
    "        # print('e shape is', e.shape)\n",
    "        attention = torch.softmax(attn, dim=-1)  # attention\n",
    "        z = torch.matmul(attention, v.permute(0, 2, 1))\n",
    "        z = z.view(batch_size, self.hidden_dim, H, W)\n",
    "        out = self.layer_f(z) + h\n",
    "\n",
    "        return out, attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d10e6c",
   "metadata": {},
   "source": [
    "# DeepMeshCity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9afaf2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "\n",
    "class DeepMeshCity(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(DeepMeshCity, self).__init__()\n",
    "        # hyperparrams\n",
    "        self.meta_in = configs.meta_dim\n",
    "        self.map_width = configs.map_width\n",
    "        self.patch_size = configs.patch_size\n",
    "        self.resize_ratio = self.map_width // self.patch_size\n",
    "        self.frame_channel = configs.map_channel\n",
    "        self.clossness_len = configs.clossness_len\n",
    "        self.periodic_len = configs.periodic_len\n",
    "        self.trend_len = configs.trend_len\n",
    "        self.device = configs.device\n",
    "\n",
    "        # Parameter for External Meta data\n",
    "        self.meta_out = self.map_width * self.map_width * self.frame_channel\n",
    "        self.is_metadate = configs.is_metadate\n",
    "        self.Meta_frame_channel = self.frame_channel * 2 if self.is_metadate else self.frame_channel\n",
    "        self.is_extra = configs.is_extra \n",
    "\n",
    "        # Parameter for Model\n",
    "        self.num_layers = configs.num_layers\n",
    "        self.num_hidden = configs.num_hidden\n",
    "        self.filter_size = configs.filter_size\n",
    "        self.stride = configs.stride\n",
    "        self.layer_norm = configs.layer_norm\n",
    "\n",
    "        # Early Fusion\n",
    "        if self.is_metadate:\n",
    "            self.meta_learn = nn.Sequential(nn.Linear(self.meta_in, 10),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Linear(10, self.meta_out),\n",
    "                                            nn.ReLU())\n",
    "        # if self.is_extra:\n",
    "        #     self.extra = # todo\n",
    "        \n",
    "        # Stacked SA-CGL Blocks\n",
    "        SACGL_blocks = []\n",
    "        for i in range(self.num_layers):\n",
    "            in_channel = self.Meta_frame_channel if i == 0 else self.num_hidden[i - 1]\n",
    "            attn_channel = in_channel * self.resize_ratio * self.resize_ratio\n",
    "            SACGL_blocks.append(nn.ModuleList([\n",
    "                self_attention(attn_channel, self.num_hidden[i]),\n",
    "                CGL(in_channel, self.num_hidden[i], self.filter_size, self.stride, self.layer_norm)\n",
    "            ]))\n",
    "\n",
    "        self.SACGL_blocks = nn.ModuleList(SACGL_blocks)\n",
    "\n",
    "        # Output Module\n",
    "        self.Output_module = nn.Sequential(\n",
    "            nn.Conv2d(self.num_hidden[self.num_layers - 1], self.num_hidden[-1],\n",
    "                      kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(self.num_hidden[-1], self.frame_channel,\n",
    "                      kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        )\n",
    "    def Attention_module(self, net, i, extra=None):\n",
    "        net = rearrange(net, 'b c (p1 h) (p2 w) -> b (h w c) p1 p2', p1=self.patch_size, p2=self.patch_size)\n",
    "        if extra is not None:\n",
    "            extra = rearrange(extra, 'b c (p1 h) (p2 w) -> b (h w c) p1 p2', p1=self.patch_size, p2=self.patch_size)\n",
    "        \n",
    "        net, _ = self.SACGL_blocks[i][0](net, net, net, extra)\n",
    "        net = rearrange(net, 'b (h w c) p1 p2 -> b c (p1 h) (p2 w)', h=self.resize_ratio, w=self.resize_ratio)\n",
    "\n",
    "        return net\n",
    "\n",
    "    def forward(self, xc, xp, xt, yd):\n",
    "        B, _, C, H, W = xc.shape\n",
    "\n",
    "        if self.is_metadate:\n",
    "            if yd.dim() > 2:\n",
    "                yd = yd.view(yd.shape[0], -1)\n",
    "            \n",
    "            yd = rearrange(self.meta_learn(yd), 'b (f c h w) -> b f c h w', c=self.frame_channel,\n",
    "                           h=self.map_width, w=self.map_width)\n",
    "\n",
    "            xcd = yd.repeat(1, self.clossness_len, 1, 1, 1) if self.clossness_len > 1 else yd\n",
    "            xpd = yd.repeat(1, self.periodic_len, 1, 1, 1) if self.periodic_len > 1 else yd\n",
    "            xtd = yd.repeat(1, self.trend_len, 1, 1, 1) if self.trend_len > 1 else yd\n",
    "\n",
    "            xp = torch.cat((xp, xpd), dim=2)\n",
    "            xt = torch.cat((xt, xtd), dim=2)\n",
    "            xc = torch.cat((xc, xcd), dim=2)\n",
    "\n",
    "        frames = torch.cat((xt, xp, xc), dim=1)\n",
    "\n",
    "        batch = frames.shape[0]\n",
    "        height = frames.shape[-2]\n",
    "        width = frames.shape[-1]\n",
    "\n",
    "        h_t = []\n",
    "        c_t = []\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            zeros = torch.zeros([batch, self.num_hidden[i], height, width]).to(self.device)\n",
    "            h_t.append(zeros)\n",
    "            c_t.append(zeros)\n",
    "\n",
    "        memory = torch.zeros([batch, self.num_hidden[0], height, width]).to(self.device)\n",
    "\n",
    "        total_length = self.clossness_len + self.periodic_len + self.trend_len\n",
    "        for t in range(total_length):\n",
    "            net = frames[:, t]\n",
    "\n",
    "            net = self.Attention_module(net, 0, extra=self.is_extra)\n",
    "            \n",
    "            h_t[0], c_t[0], memory = self.SACGL_blocks[0][1](net, c_t[0], memory)\n",
    "\n",
    "            for i in range(1, self.num_layers):\n",
    "                h_t[i - 1] = self.Attention_module(h_t[i - 1], i, extra=self.is_extra)\n",
    "                h_t[i], c_t[i], memory = self.SACGL_blocks[i][1](h_t[i - 1], c_t[i], memory)\n",
    "\n",
    "        x_gen = self.Output_module(h_t[self.num_layers - 1])\n",
    "        return x_gen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b631bd",
   "metadata": {},
   "source": [
    "# model_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6382fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(configs):\n",
    "    networks_map = {\n",
    "        'DeepMeshCity_TPE': DeepMeshCity,\n",
    "    }\n",
    "    model_type = configs.model_type\n",
    "\n",
    "    if model_type in networks_map:\n",
    "        Network = networks_map[model_type]\n",
    "        network = Network(configs).to(configs.device)\n",
    "        return network\n",
    "    else:\n",
    "        raise ValueError('Name of network unknown %s' % model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ec5dc",
   "metadata": {},
   "source": [
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c559f474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os.path\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "\n",
    "def evaluate_model(model, MSE_criterion, DataLoader, device, configs, is_save, itr=999):\n",
    "    print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'test...')\n",
    "\n",
    "    res_path = os.path.join(configs.gen_frm_dir, str(itr))\n",
    "    if not os.path.exists(res_path):\n",
    "        os.mkdir(res_path)\n",
    "    avg_mse = 0\n",
    "    avg_rmse = 0\n",
    "    avg_mae = 0\n",
    "    correct_count = 0\n",
    "    item_count = 0\n",
    "    batch_id = 0\n",
    "\n",
    "    loss_list = []\n",
    "    model.eval()\n",
    "    all_tre = []\n",
    "    with torch.no_grad():\n",
    "        for batch, item in enumerate(DataLoader):\n",
    "            batch_id = batch_id + 1\n",
    "            item_count = item_count+1\n",
    "            xc, xp, xt, ys, yd = item\n",
    "            xc, xp, xt, ys, yd = list(map(lambda x: x.to(device), [xc, xp, xt, ys, yd]))\n",
    "            pred = model(xc, xp, xt, yd)\n",
    "            loss = MSE_criterion(pred, ys)\n",
    "            loss_item = loss.cpu().item()\n",
    "            loss_list.append(loss_item)\n",
    "            #print(\"validation:batch \",batch,\"loss=\",loss_item)\n",
    "            # MSE per frame\n",
    "            x = ys.cpu().numpy() * configs.max_value  # (B, H, W, C)\n",
    "            print(x.shape)\n",
    "            gx = pred.cpu().numpy() * configs.max_value\n",
    "            # gx[gx < 1] = 0\n",
    "            \n",
    "            mae = np.mean(np.abs(x - gx))\n",
    "            mse = np.mean(np.square(x - gx))\n",
    "            rmse = np.mean(np.square(x - gx))\n",
    "            \n",
    "            avg_mae += mae\n",
    "            avg_mse += mse\n",
    "            avg_rmse += rmse\n",
    "            # TRE\n",
    "            \n",
    "            B = x.shape[0]  # 每個 batch 中有 B 筆資料\n",
    "            for i in range(B):\n",
    "                correct = np.sum(np.abs(x[i] - gx[i]) < 1)\n",
    "                total = x[i].size\n",
    "                tre = (1 - correct / total) * 100\n",
    "                all_tre.append(tre)\n",
    "                # draw \n",
    "                error = x[i] - gx[i]\n",
    "                error = np.squeeze(x[i] - gx[i])\n",
    "                \n",
    "                fig = sns.heatmap(error, annot=True,annot_kws={\"size\": 3}, fmt=\".3f\", vmin=0, xticklabels=False,\n",
    "                      yticklabels=False, cbar=False, cmap='rainbow', square=True)\n",
    "                heatmap = fig.get_figure()\n",
    "                heatmap.savefig(os.path.join(\"error_map\", f\"error_map_{i}.png\"), dpi=300, bbox_inches='tight')\n",
    "                plt.clf()\n",
    "                # debug\n",
    "                fig = sns.heatmap(np.squeeze(x[i]), annot=True,annot_kws={\"size\": 3}, fmt=\".3f\", vmin=0, xticklabels=False,\n",
    "                      yticklabels=False, cbar=False, cmap='rainbow', square=True)\n",
    "                heatmap = fig.get_figure()\n",
    "                heatmap.savefig(os.path.join(\"error_map\", f\"true_{i}.png\"), dpi=300, bbox_inches='tight')\n",
    "                plt.clf()\n",
    "            # save prediction examples\n",
    "            if batch_id <= configs.num_save_samples:\n",
    "                path = os.path.join(res_path, str(batch_id))\n",
    "                if not os.path.exists(path):\n",
    "                    os.mkdir(path)\n",
    "                for i in range(configs.input_length):\n",
    "                    name = 'gt' + str(i + 1) + '.png'\n",
    "                    file_name = os.path.join(path, name)\n",
    "                    img_c = xc[0, i, 0, :, :].cpu().numpy()\n",
    "                    draw_pic(img_c, file_name, configs.max_value)\n",
    "\n",
    "                name = 'pd7' + '.png'\n",
    "                file_name = os.path.join(path, name)\n",
    "                img_pd = pred[0, 0, :, :].cpu().numpy()\n",
    "                draw_pic(img_pd, file_name, configs.max_value)\n",
    "\n",
    "                name = 'gt7' + '.png'\n",
    "                file_name = os.path.join(path, name)\n",
    "                img_gt = ys[0, 0, :, :].cpu().numpy()\n",
    "                draw_pic(img_gt, file_name, configs.max_value)\n",
    "\n",
    "        avg_mse = avg_mse / batch_id\n",
    "        avg_mae = avg_mae / batch_id\n",
    "        avg_rmse = np.sqrt(avg_rmse / batch_id)\n",
    "        \n",
    "        # TRE\n",
    "        # total_pixels = x.size * batch_id\n",
    "        # tre = (1 - correct_count / total_pixels) * 100\n",
    "        avg_tre = np.mean(all_tre)\n",
    "        print('mse per frame: {}, rmse per frame: {}, mae per frame: {}, avg_tre : {} %'.format(avg_mse, avg_rmse, avg_mae,tre))\n",
    "        if(is_save):\n",
    "            save_dir = \"report\"\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            now_str = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            log_path = os.path.join(save_dir, now_str + \".txt\")\n",
    "            with open(log_path, \"w\") as log_file:\n",
    "                log_file.write('mse per frame: {}, rmse per frame: {}, mae per frame: {}, avg_tre : {} %'.format(avg_mse, avg_rmse, avg_mae,tre))\n",
    "        # save tre\n",
    "        with open(\"report/individual_tre.txt\", \"w\") as f:\n",
    "            for i, tre in enumerate(all_tre):\n",
    "                f.write(f\"Sample {i}: TRE = {tre:.2f}%\\n\")\n",
    "    return avg_mse, avg_rmse, avg_mae, tre\n",
    "\n",
    "\n",
    "def draw_pic(img_gt, file_name,denorm_factor=1.0 ):\n",
    "    img_gt[img_gt > 0.2] = 0.2\n",
    "    factor = 1.0 / 3.0\n",
    "    img_gt[(img_gt > 0.05) & (img_gt <= 0.2)] = img_gt[(img_gt > 0.05) & (img_gt <= 0.2)] * factor + 2 * factor * 0.05\n",
    "    img_gt = img_gt * denorm_factor\n",
    "    fig = sns.heatmap(img_gt, annot=True,annot_kws={\"size\": 3}, fmt=\".3f\", vmin=0, xticklabels=False,\n",
    "                      yticklabels=False, cbar=False, cmap='rainbow', square=True)\n",
    "    heatmap = fig.get_figure()\n",
    "    heatmap.savefig(file_name, dpi=300, bbox_inches='tight')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd882ab",
   "metadata": {},
   "source": [
    "# evaluate_model_with_custom_YD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79ca1235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_custom_YD(model, DataLoader, MSE_criterion, device, target_feature_idx, configs):\n",
    "    print(\"evaluate_model_with_custom_YD:\", target_feature_idx)\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_count = 0\n",
    "    batch_id = 0\n",
    "    avg_mse = 0\n",
    "    avg_rmse = 0\n",
    "    avg_mae = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, item in enumerate(DataLoader):\n",
    "            batch_id = batch_id + 1\n",
    "            xc, xp, xt, ys, yd = item\n",
    "            XC = xc.to(device)\n",
    "            XP = xp.to(device)\n",
    "            XT = xt.to(device)\n",
    "            YS = ys.to(device)\n",
    "            YD = yd.to(device)\n",
    "            print(\"YD shape:\", YD.shape)\n",
    "\n",
    "            YD_modified = YD.clone()\n",
    "            YD_modified[:, target_feature_idx] = 0  \n",
    "\n",
    "            pred = model(XC, XP, XT, YD_modified)\n",
    "            loss = MSE_criterion(pred, YS)\n",
    "            # MSE per frame\n",
    "            x = ys.cpu().numpy() * configs.max_value  # (B, H, W, C)\n",
    "            gx = pred.cpu().numpy() * configs.max_value\n",
    "            # gx[gx < 1] = 0\n",
    "            \n",
    "            mae = np.mean(np.abs(x - gx))\n",
    "            mse = np.mean(np.square(x - gx))\n",
    "            rmse = np.mean(np.square(x - gx))\n",
    "            \n",
    "            avg_mae += mae\n",
    "            avg_mse += mse\n",
    "            avg_rmse += rmse\n",
    "            # TRE\n",
    "            correct_count += np.sum(np.abs(x - gx) < 1)\n",
    "    avg_mse = avg_mse / batch_id\n",
    "    avg_mae = avg_mae / batch_id\n",
    "    avg_rmse = np.sqrt(avg_rmse / batch_id)\n",
    "\n",
    "    # TRE\n",
    "    total_pixels = x.size * batch_id\n",
    "    tre = (1 - correct_count / total_pixels) * 100\n",
    "    return avg_mse, avg_rmse, avg_mae, tre\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a87b2c0",
   "metadata": {},
   "source": [
    "# trainer_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99ec1542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, loss_func, dataloader, lr_scheduler, epoch, device):\n",
    "    loss_list = []\n",
    "    model.train()\n",
    "    print(\"The learning rate of the %dth epoch：%f\" % (epoch, optimizer.param_groups[0]['lr']))\n",
    "    for batch, item in tqdm(enumerate(dataloader)):\n",
    "        xc, xp, xt, ys, yd = item\n",
    "        xc, xp, xt, ys, yd = list(map(lambda x: Variable(x.to(device)), [xc, xp, xt, ys, yd]))\n",
    "        optimizer.zero_grad()\n",
    "        next_frame = model(xc, xp, xt, yd)\n",
    "        loss = loss_func(next_frame, ys)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_item = loss.cpu().item()\n",
    "        #print(\"train: batch \",batch,\"loss=\",loss_item)\n",
    "        loss_list.append(loss_item)\n",
    "\n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step(epoch)\n",
    "\n",
    "    return sum(loss_list) / len(loss_list)\n",
    "\n",
    "\n",
    "def test_epoch(model, loss_func, DataLoader, device):\n",
    "    loss_list = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, item in tqdm(enumerate(DataLoader)):\n",
    "            xc, xp, xt, ys, yd = item\n",
    "            xc, xp, xt, ys, yd = list(map(lambda x: x.to(device), [xc, xp, xt, ys, yd]))\n",
    "            next_frame = model(xc, xp, xt, yd)\n",
    "\n",
    "            loss = loss_func(next_frame, ys)\n",
    "            loss_list.append(loss.detach().cpu().item())\n",
    "\n",
    "    return sum(loss_list) / len(loss_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a43a8f7",
   "metadata": {},
   "source": [
    "# trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d7fb989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_curves(train_loss_epoch, val_loss_epoch, tre_epoch, save_dir='loss_plots'):\n",
    "    \"\"\"\n",
    "    畫出訓練/驗證 loss 曲線與 tre_epoch 變化，並分別儲存圖片。\n",
    "    :param train_loss_epoch: List of training losses per epoch\n",
    "    :param val_loss_epoch: List of validation losses per epoch\n",
    "    :param tre_epoch: List of \"tre\" values per epoch\n",
    "    :param save_dir: Directory to save the plots\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.figure()\n",
    "    plt.plot(train_loss_epoch, label='Train Loss', color='blue')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss over Epochs')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'train_loss.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot validation loss\n",
    "    plt.figure()\n",
    "    plt.plot(val_loss_epoch, label='Validation Loss', color='green')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Validation Loss over Epochs')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'val_loss.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot TRE (or third metric)\n",
    "    plt.figure()\n",
    "    plt.plot(tre_epoch, label='TRE', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('TRE')\n",
    "    plt.title('TRE over Epochs')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'tre.png'))\n",
    "    plt.close()\n",
    "\n",
    "def  train_main(cfg, save = False):\n",
    "    # config\n",
    "    train_cfg = cfg.train_cfg\n",
    "    dataset_cfg = cfg.dataset_cfg\n",
    "    model_cfg = cfg.model_cfg\n",
    "    device = cfg.device\n",
    "\n",
    "    # dataset\n",
    "    train_dataset = Dataset_TPE(dataset_cfg, mode='train')\n",
    "    val_dataset = Dataset_TPE(dataset_cfg, mode='valid')\n",
    "    train_loader = DataLoader(train_dataset, batch_size=train_cfg.batch_size, shuffle=True, pin_memory=True,\n",
    "                              drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=train_cfg.batch_size, shuffle=False, pin_memory=True,\n",
    "                            drop_last=True)\n",
    "\n",
    "    print(train_cfg.optimizer_cfg)\n",
    "    # build model\n",
    "    model = build_model(model_cfg).to(device)\n",
    "\n",
    "    # whether Parallel\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "    if torch.cuda.device_count() == 1:\n",
    "        print(\"there is 1 GPU\")\n",
    "    parameters = model.parameters()\n",
    "\n",
    "    # Parameter information\n",
    "    print('Net\\'s state_dict:')\n",
    "    total_param = 0\n",
    "    for param_tensor in model.state_dict():\n",
    "        print(param_tensor, '\\t', model.state_dict()[param_tensor].size())\n",
    "        total_param += np.prod(model.state_dict()[param_tensor].size())\n",
    "    print('Net\\'s total params:', total_param)\n",
    "\n",
    "    # loss\n",
    "    MSE_criterion = nn.MSELoss().to(device)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer_cfg = train_cfg.optimizer_cfg\n",
    "    lr_scheduler_cfg = train_cfg.lr_scheduler_cfg\n",
    "    if optimizer_cfg.type == 'adam':\n",
    "        optimizer = optim.Adam(params=parameters,\n",
    "                               lr=optimizer_cfg.lr)\n",
    "    elif optimizer_cfg.type == 'adamw':\n",
    "        optimizer = optim.AdamW(params=parameters,\n",
    "                                lr=optimizer_cfg.lr,\n",
    "                                weight_decay=optimizer_cfg.weight_decay)\n",
    "    elif optimizer_cfg.type == 'sgd':\n",
    "        optimizer = optim.SGD(params=parameters,\n",
    "                              lr=optimizer_cfg.lr,\n",
    "                              momentum=optimizer_cfg.momentum,\n",
    "                              weight_decay=optimizer_cfg.weight_decay)\n",
    "    elif optimizer_cfg.type == 'RMS':\n",
    "        optimizer = optim.RMSprop(params=parameters,\n",
    "                                  lr=optimizer_cfg.lr,\n",
    "                                  momentum=optimizer_cfg.momentum,\n",
    "                                  weight_decay=optimizer_cfg.weight_decay)\n",
    "    else:\n",
    "        raise Exception('No Optimizer！')\n",
    "\n",
    "    # learning schedule\n",
    "    if lr_scheduler_cfg is None:\n",
    "        lr_scheduler = None\n",
    "    elif lr_scheduler_cfg.policy == 'step':\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, lr_scheduler_cfg.step_size,\n",
    "                                                       gamma=lr_scheduler_cfg.gamma, last_epoch=-1)\n",
    "    elif lr_scheduler_cfg.policy == 'cos':\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, lr_scheduler_cfg.T_0,\n",
    "                                                                            lr_scheduler_cfg.T_mult,\n",
    "                                                                            lr_scheduler_cfg.eta_min)\n",
    "    else:\n",
    "        lr_scheduler = None\n",
    "\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    Best_Metric = 0\n",
    "    Min_Metric = 999999999\n",
    "    best_epoch = 0\n",
    "    check_point_dir = '/'.join(train_cfg.check_point_file.split('/')[:-1])\n",
    "\n",
    "    if not os.path.exists(check_point_dir):\n",
    "        os.mkdir(check_point_dir)\n",
    "    train_loss_epoch = []\n",
    "    val_loss_epoch = []\n",
    "    tre_epoch = []\n",
    "    print(\"train_cfg.num_epochs = \", train_cfg.num_epochs)\n",
    "    for epoch in range(1, train_cfg.num_epochs + 1):\n",
    "        print()\n",
    "        print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "        start_time = time.time()\n",
    "        print(f\"It is the {epoch}th epoch...\")\n",
    "\n",
    "        # training\n",
    "        train_loss = train_epoch(model, optimizer, MSE_criterion, train_loader, lr_scheduler, epoch, device)\n",
    "        if epoch % train_cfg.test_interval == 0:\n",
    "            # validate\n",
    "            val_loss = evaluate_model(model, MSE_criterion, val_loader, device, train_cfg, epoch, False)\n",
    "            Best_Metric = val_loss[0]\n",
    "\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "        # save model\n",
    "        if Min_Metric > Best_Metric:\n",
    "            Min_Metric = Best_Metric\n",
    "            best_epoch = epoch\n",
    "            torch.save(model, train_cfg.check_point_file)\n",
    "\n",
    "        if epoch == 75 or epoch == 155 or epoch == train_cfg.num_epochs or save == True:\n",
    "            now = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            model_file = train_cfg.check_point_file.split('.')[0] + f'.pth'\n",
    "            torch.save(model, model_file)\n",
    "\n",
    "        # print out\n",
    "        test_end_time = time.time()\n",
    "        run_time = int(test_end_time - start_time)\n",
    "        m, s = divmod(run_time, 60)\n",
    "        time_str = \"{:02d}m{:02d}s\".format(m, s)\n",
    "        out_str = \"The {} epoch is finished, consuming {},\\n\" \\\n",
    "                  \"The loss on training set is {:.6f}；the best epoch is {}, best_metric={:.6f}\" \\\n",
    "            .format(epoch, time_str, sum(train_loss_list) / len(train_loss_list), best_epoch, Min_Metric)\n",
    "        print(out_str)\n",
    "        train_loss_epoch.append(sum(train_loss_list) / len(train_loss_list))\n",
    "        val_loss_epoch.append(Best_Metric)\n",
    "        tre_epoch.append(val_loss[3])\n",
    "    # draw train_loss_epoch & val_loss_epoch\n",
    "    plot_loss_curves(train_loss_epoch, val_loss_epoch, tre_epoch)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fb2252",
   "metadata": {},
   "source": [
    "# Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a03d9973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "\n",
    "def test_main(cfg):\n",
    "    # config\n",
    "    test_cfg = cfg.test_cfg\n",
    "    dataset_cfg = cfg.dataset_cfg\n",
    "    device = cfg.device\n",
    "    model_cfg = cfg.model_cfg\n",
    "\n",
    "    # dataset\n",
    "    test_dataset = Dataset_TPE(dataset_cfg, mode='test')\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_cfg.batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "    \n",
    "    # loss\n",
    "    model = build_model(model_cfg).to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    MSE_criterion = nn.MSELoss().to(device)\n",
    "    model_file = test_cfg.check_point_file\n",
    "    checkpoint = torch.load(model_file, map_location=device, weights_only=False)\n",
    "    model.load_state_dict(checkpoint.state_dict())\n",
    "    print(\"test_loader.dataset\",test_loader.dataset)\n",
    "    test_loss = evaluate_model(model, MSE_criterion, test_loader, device, test_cfg,True)\n",
    "    print('The loss on test set is {:.6f}'.format(test_loss[0]))\n",
    "\n",
    "    now_str = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"{now_str} test...\\n\")\n",
    "    \n",
    "    # ablation\n",
    "    \n",
    "    M = 14\n",
    "    importances = []\n",
    "\n",
    "    for i in range(7, M):\n",
    "        loss_i = evaluate_model_with_custom_YD(model, test_loader, MSE_criterion, device, i, test_cfg)\n",
    "        \n",
    "        importance = loss_i[0] - test_loss[0]\n",
    "        importances.append(importance)\n",
    "    print(importances)\n",
    "    # 畫出 bar chart\n",
    "    import matplotlib.pyplot as plt\n",
    "    feature_names = [\"workday\", \"rush hour\" ,\"weekend\" ,\"holiday\" ,\"make-up workday\" ,\"day of week\" ,\"weather\"]\n",
    "    plt.bar(range(7), importances)\n",
    "    plt.xticks(ticks=range(7), labels=feature_names, rotation=45, ha='right')\n",
    "    plt.xlabel(\"External Feature Index\")\n",
    "    plt.ylabel(\"Importance (Loss Increase)\")\n",
    "    plt.title(\"Feature Importance by Ablation\")\n",
    "    plt.savefig(\"feature_importance.png\", dpi=300, bbox_inches='tight')  # 存成 PNG\n",
    "    plt.close()\n",
    "    # # 假設 model 已經 load 完畢\n",
    "    # model_state = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()\n",
    "\n",
    "    # # 儲存資料夾\n",
    "    # save_dir = \"weights_txt\"\n",
    "    # os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # for name, param in model_state.items():\n",
    "    #     if 'weight' in name:\n",
    "    #         weight_np = param.detach().cpu().numpy()\n",
    "    #         save_path = os.path.join(save_dir, f\"{name.replace('.', '_')}.txt\")\n",
    "    #         np.savetxt(save_path, weight_np.flatten(), fmt=\"%.6f\")\n",
    "    #         print(f\"Saved {name} to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281f7625",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac4fc0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import sys\n",
    "from argparse import ArgumentParser\n",
    "from importlib import import_module\n",
    "\n",
    "from addict import Dict\n",
    "\n",
    "# from .misc import collections_abc\n",
    "\n",
    "\n",
    "class ConfigDict(Dict):\n",
    "    def __missing__(self, name):\n",
    "        raise KeyError(name)\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            value = super(ConfigDict, self).__getattr__(name)\n",
    "        except KeyError:\n",
    "            ex = AttributeError(\n",
    "                \"'{}' object has no attribute '{}'\".format(\n",
    "                    self.__class__.__name__, name\n",
    "                )\n",
    "            )\n",
    "        except Exception as e:\n",
    "            ex = e\n",
    "        else:\n",
    "            return value\n",
    "        raise ex\n",
    "\n",
    "\n",
    "def add_args(parser, cfg, prefix=\"\"):\n",
    "    for k, v in cfg.items():\n",
    "        if isinstance(v, str):\n",
    "            parser.add_argument(\"--\" + prefix + k)\n",
    "        elif isinstance(v, int):\n",
    "            parser.add_argument(\"--\" + prefix + k, type=int)\n",
    "        elif isinstance(v, float):\n",
    "            parser.add_argument(\"--\" + prefix + k, type=float)\n",
    "        elif isinstance(v, bool):\n",
    "            parser.add_argument(\"--\" + prefix + k, action=\"store_true\")\n",
    "        elif isinstance(v, dict):\n",
    "            add_args(parser, v, k + \".\")\n",
    "        # elif isinstance(v, collections_abc.Iterable):\n",
    "        #     parser.add_argument(\"--\" + prefix + k, type=type(v[0]), nargs=\"+\")\n",
    "        else:\n",
    "            print(\"connot parse key {} of type {}\".format(prefix + k, type(v)))\n",
    "    return parser\n",
    "\n",
    "\n",
    "class Config(object):\n",
    "    \"\"\"A facility for config and config files.\n",
    "    It supports common file formats as configs: python/json/yaml. The interface\n",
    "    is the same as a dict object and also allows access config values as\n",
    "    attributes.\n",
    "    Example:\n",
    "        >>> cfg = Config(dict(a=1, b=dict(b1=[0, 1])))\n",
    "        >>> cfg.a\n",
    "        1\n",
    "        >>> cfg.b\n",
    "        {'b1': [0, 1]}\n",
    "        >>> cfg.b.b1\n",
    "        [0, 1]\n",
    "        >>> cfg = Config.fromfile('tests/data/config/a.py')\n",
    "        >>> cfg.filename\n",
    "        \"/home/kchen/projects/torchie/tests/data/config/a.py\"\n",
    "        >>> cfg.item4\n",
    "        'test'\n",
    "        >>> cfg\n",
    "        \"Config [path: /home/kchen/projects/torchie/tests/data/config/a.py]: \"\n",
    "        \"{'item1': [1, 2], 'item2': {'a': 0}, 'item3': True, 'item4': 'test'}\"\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def fromfile(filename):\n",
    "        filename = osp.abspath(osp.expanduser(filename))\n",
    "        if not osp.isfile(filename):\n",
    "            raise FileNotFoundError('file \"{}\" does not exist'.format(filename))\n",
    "\n",
    "        if filename.endswith(\".py\"):\n",
    "            module_name = osp.basename(filename)[:-3]\n",
    "            if \".\" in module_name:\n",
    "                raise ValueError(\"Dots are not allowed in config file path.\")\n",
    "            config_dir = osp.dirname(filename)\n",
    "            sys.path.insert(0, config_dir)\n",
    "            mod = import_module(module_name)\n",
    "            sys.path.pop(0)\n",
    "            cfg_dict = {\n",
    "                name: value\n",
    "                for name, value in mod.__dict__.items()\n",
    "                if not name.startswith(\"__\")\n",
    "            }\n",
    "        elif filename.endswith((\".yml\", \".yaml\", \".json\")):\n",
    "            import torchie\n",
    "\n",
    "            cfg_dict = torchie.load(filename)\n",
    "        else:\n",
    "            raise IOError(\"Only py/yml/yaml/json type are supported now!\")\n",
    "        return Config(cfg_dict, filename=filename)\n",
    "\n",
    "    @staticmethod\n",
    "    def auto_argparser(description=None):\n",
    "        \"\"\"Generate argparser from config file automatically (experimental)\n",
    "        \"\"\"\n",
    "        partial_parser = ArgumentParser(description=description)\n",
    "        partial_parser.add_argument(\"config\", help=\"config file path\")\n",
    "        cfg_file = partial_parser.parse_known_args()[0].config\n",
    "        cfg = Config.fromfile(cfg_file)\n",
    "        parser = ArgumentParser(description=description)\n",
    "        parser.add_argument(\"config\", help=\"config file path\")\n",
    "        add_args(parser, cfg)\n",
    "        return parser, cfg\n",
    "\n",
    "    def __init__(self, cfg_dict=None, filename=None):\n",
    "        if cfg_dict is None:\n",
    "            cfg_dict = dict()\n",
    "        elif not isinstance(cfg_dict, dict):\n",
    "            raise TypeError(\n",
    "                \"cfg_dict must be a dict, but got {}\".format(type(cfg_dict))\n",
    "            )\n",
    "\n",
    "        super(Config, self).__setattr__(\"_cfg_dict\", ConfigDict(cfg_dict))\n",
    "        super(Config, self).__setattr__(\"_filename\", filename)\n",
    "        if filename:\n",
    "            with open(filename, \"r\") as f:\n",
    "                super(Config, self).__setattr__(\"_text\", f.read())\n",
    "        else:\n",
    "            super(Config, self).__setattr__(\"_text\", \"\")\n",
    "\n",
    "    @property\n",
    "    def filename(self):\n",
    "        return self._filename\n",
    "\n",
    "    @property\n",
    "    def text(self):\n",
    "        return self._text\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Config (path: {}): {}\".format(self.filename, self._cfg_dict.__repr__())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._cfg_dict)\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._cfg_dict, name)\n",
    "\n",
    "    def __getitem__(self, name):\n",
    "        return self._cfg_dict.__getitem__(name)\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if isinstance(value, dict):\n",
    "            value = ConfigDict(value)\n",
    "        self._cfg_dict.__setattr__(name, value)\n",
    "\n",
    "    def __setitem__(self, name, value):\n",
    "        if isinstance(value, dict):\n",
    "            value = ConfigDict(value)\n",
    "        self._cfg_dict.__setitem__(name, value)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self._cfg_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee12c91",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "477bfd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config filename: DeepMeshCity_TPE_flow_config.py\n",
      "random seed is 6666\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "cfg_filename = \"DeepMeshCity_TPE_flow_config.py\"  # config filename\n",
    "data = \"TPE\"\n",
    "task = \"flow\"  # flow,density\n",
    "\n",
    "# read config\n",
    "cfg = Config.fromfile('./Config/' + data + '/' + task + '/' + cfg_filename)\n",
    "print(\"config filename: \" + str(cfg_filename))\n",
    "\n",
    "set_seed(cfg.random_seed)\n",
    "print(\"random seed is {}\".format(cfg.random_seed))\n",
    "\n",
    "split_save_dir = cfg.train_cfg.check_point_file.split('/')\n",
    "save_dir = os.path.join(split_save_dir[0], os.path.join(split_save_dir[1], split_save_dir[2]))\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "if not os.path.exists(cfg.train_cfg.gen_frm_dir):\n",
    "    os.makedirs(cfg.train_cfg.gen_frm_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce174542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'input_length': 6,\n",
       " 'num_epochs': 5,\n",
       " 'max_value': 32,\n",
       " 'test_interval': 1,\n",
       " 'num_save_samples': 3,\n",
       " 'optimizer_cfg': {'type': 'adamw', 'lr': 0.001, 'weight_decay': 0.0005},\n",
       " 'lr_scheduler_cfg': {'policy': 'cos',\n",
       "  'T_0': 5,\n",
       "  'T_mult': 2,\n",
       "  'eta_min': 1e-05},\n",
       " 'check_point_file': 'checkpoint/TPE/flow/DeepMeshCity.pth',\n",
       " 'gen_frm_dir': 'Results/TPE/flow/DeepMeshCity'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.train_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00cbcc",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "565b9f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7377, 6, 1, 28, 28) (7377, 1, 1, 28, 28) (7377, 1, 1, 28, 28) (7377, 1, 28, 28) (7377, 32) 1292.0\n",
      "(1053, 6, 1, 28, 28) (1053, 1, 1, 28, 28) (1053, 1, 1, 28, 28) (1053, 1, 28, 28) (1053, 32) 1292.0\n",
      "{'type': 'adamw', 'lr': 0.001, 'weight_decay': 0.0005}\n",
      "there is 1 GPU\n",
      "Net's state_dict:\n",
      "meta_learn.0.weight \t torch.Size([10, 32])\n",
      "meta_learn.0.bias \t torch.Size([10])\n",
      "meta_learn.2.weight \t torch.Size([784, 10])\n",
      "meta_learn.2.bias \t torch.Size([784])\n",
      "SACGL_blocks.0.0.layer_q.weight \t torch.Size([64, 32, 1, 1])\n",
      "SACGL_blocks.0.0.layer_q.bias \t torch.Size([64])\n",
      "SACGL_blocks.0.0.layer_k.weight \t torch.Size([64, 32, 1, 1])\n",
      "SACGL_blocks.0.0.layer_k.bias \t torch.Size([64])\n",
      "SACGL_blocks.0.0.layer_v.weight \t torch.Size([64, 32, 1, 1])\n",
      "SACGL_blocks.0.0.layer_v.bias \t torch.Size([64])\n",
      "SACGL_blocks.0.0.layer_f.weight \t torch.Size([32, 64, 1, 1])\n",
      "SACGL_blocks.0.0.layer_f.bias \t torch.Size([32])\n",
      "SACGL_blocks.0.1.conv_x.0.weight \t torch.Size([256, 2, 3, 3])\n",
      "SACGL_blocks.0.1.conv_x.0.bias \t torch.Size([256])\n",
      "SACGL_blocks.0.1.conv_x.1.weight \t torch.Size([256])\n",
      "SACGL_blocks.0.1.conv_x.1.bias \t torch.Size([256])\n",
      "SACGL_blocks.0.1.conv_c.0.weight \t torch.Size([128, 64, 3, 3])\n",
      "SACGL_blocks.0.1.conv_c.0.bias \t torch.Size([128])\n",
      "SACGL_blocks.0.1.conv_c.1.weight \t torch.Size([128])\n",
      "SACGL_blocks.0.1.conv_c.1.bias \t torch.Size([128])\n",
      "SACGL_blocks.0.1.conv_m.0.weight \t torch.Size([128, 64, 3, 3])\n",
      "SACGL_blocks.0.1.conv_m.0.bias \t torch.Size([128])\n",
      "SACGL_blocks.0.1.conv_m.1.weight \t torch.Size([128])\n",
      "SACGL_blocks.0.1.conv_m.1.bias \t torch.Size([128])\n",
      "SACGL_blocks.0.1.conv_o_c.0.weight \t torch.Size([64, 128, 1, 1])\n",
      "SACGL_blocks.0.1.conv_o_c.0.bias \t torch.Size([64])\n",
      "SACGL_blocks.0.1.conv_o_c.1.weight \t torch.Size([64])\n",
      "SACGL_blocks.0.1.conv_o_c.1.bias \t torch.Size([64])\n",
      "SACGL_blocks.0.1.conv_last.weight \t torch.Size([64, 128, 1, 1])\n",
      "SACGL_blocks.0.1.conv_last.bias \t torch.Size([64])\n",
      "SACGL_blocks.1.0.layer_q.weight \t torch.Size([64, 1024, 1, 1])\n",
      "SACGL_blocks.1.0.layer_q.bias \t torch.Size([64])\n",
      "SACGL_blocks.1.0.layer_k.weight \t torch.Size([64, 1024, 1, 1])\n",
      "SACGL_blocks.1.0.layer_k.bias \t torch.Size([64])\n",
      "SACGL_blocks.1.0.layer_v.weight \t torch.Size([64, 1024, 1, 1])\n",
      "SACGL_blocks.1.0.layer_v.bias \t torch.Size([64])\n",
      "SACGL_blocks.1.0.layer_f.weight \t torch.Size([1024, 64, 1, 1])\n",
      "SACGL_blocks.1.0.layer_f.bias \t torch.Size([1024])\n",
      "SACGL_blocks.1.1.conv_x.0.weight \t torch.Size([256, 64, 3, 3])\n",
      "SACGL_blocks.1.1.conv_x.0.bias \t torch.Size([256])\n",
      "SACGL_blocks.1.1.conv_x.1.weight \t torch.Size([256])\n",
      "SACGL_blocks.1.1.conv_x.1.bias \t torch.Size([256])\n",
      "SACGL_blocks.1.1.conv_c.0.weight \t torch.Size([128, 64, 3, 3])\n",
      "SACGL_blocks.1.1.conv_c.0.bias \t torch.Size([128])\n",
      "SACGL_blocks.1.1.conv_c.1.weight \t torch.Size([128])\n",
      "SACGL_blocks.1.1.conv_c.1.bias \t torch.Size([128])\n",
      "SACGL_blocks.1.1.conv_m.0.weight \t torch.Size([128, 64, 3, 3])\n",
      "SACGL_blocks.1.1.conv_m.0.bias \t torch.Size([128])\n",
      "SACGL_blocks.1.1.conv_m.1.weight \t torch.Size([128])\n",
      "SACGL_blocks.1.1.conv_m.1.bias \t torch.Size([128])\n",
      "SACGL_blocks.1.1.conv_o_c.0.weight \t torch.Size([64, 128, 1, 1])\n",
      "SACGL_blocks.1.1.conv_o_c.0.bias \t torch.Size([64])\n",
      "SACGL_blocks.1.1.conv_o_c.1.weight \t torch.Size([64])\n",
      "SACGL_blocks.1.1.conv_o_c.1.bias \t torch.Size([64])\n",
      "SACGL_blocks.1.1.conv_last.weight \t torch.Size([64, 128, 1, 1])\n",
      "SACGL_blocks.1.1.conv_last.bias \t torch.Size([64])\n",
      "Output_module.0.weight \t torch.Size([64, 64, 1, 1])\n",
      "Output_module.2.weight \t torch.Size([1, 64, 1, 1])\n",
      "Net's total params: 768218\n",
      "train_cfg.num_epochs =  5\n",
      "\n",
      "2025-06-26 02:37:49\n",
      "It is the 1th epoch...\n",
      "The learning rate of the 1th epoch：0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 148\u001b[39m, in \u001b[36mtrain_main\u001b[39m\u001b[34m(cfg, save)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIt is the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mth epoch...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    147\u001b[39m \u001b[38;5;66;03m# training\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMSE_criterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m epoch % train_cfg.test_interval == \u001b[32m0\u001b[39m:\n\u001b[32m    150\u001b[39m     \u001b[38;5;66;03m# validate\u001b[39;00m\n\u001b[32m    151\u001b[39m     val_loss = evaluate_model(model, MSE_criterion, val_loader, device, train_cfg, epoch, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, optimizer, loss_func, dataloader, lr_scheduler, epoch, device)\u001b[39m\n\u001b[32m      8\u001b[39m model.train()\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mThe learning rate of the \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33mth epoch：\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[33m\"\u001b[39m % (epoch, optimizer.param_groups[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m]))\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myd\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myd\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mxc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\work\\DeepMeshCity\\testenv\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\work\\DeepMeshCity\\testenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\work\\DeepMeshCity\\testenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:763\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m     index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    764\u001b[39m     data = \u001b[38;5;28mself\u001b[39m._dataset_fetcher.fetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\work\\DeepMeshCity\\testenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:698\u001b[39m, in \u001b[36m_BaseDataLoaderIter._next_index\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_index\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sampler_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\work\\DeepMeshCity\\testenv\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:341\u001b[39m, in \u001b[36mBatchSampler.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.drop_last:\n\u001b[32m    339\u001b[39m     \u001b[38;5;66;03m# Create multiple references to the same iterator\u001b[39;00m\n\u001b[32m    340\u001b[39m     args = [sampler_iter] * \u001b[38;5;28mself\u001b[39m.batch_size\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_droplast\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbatch_droplast\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\work\\DeepMeshCity\\testenv\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:197\u001b[39m, in \u001b[36mRandomSampler.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m torch.randint(\n\u001b[32m    191\u001b[39m         high=n,\n\u001b[32m    192\u001b[39m         size=(\u001b[38;5;28mself\u001b[39m.num_samples % \u001b[32m32\u001b[39m,),\n\u001b[32m    193\u001b[39m         dtype=torch.int64,\n\u001b[32m    194\u001b[39m         generator=generator,\n\u001b[32m    195\u001b[39m     ).tolist()\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_samples\u001b[49m // n):\n\u001b[32m    198\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m torch.randperm(n, generator=generator).tolist()\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m torch.randperm(n, generator=generator).tolist()[\n\u001b[32m    200\u001b[39m         : \u001b[38;5;28mself\u001b[39m.num_samples % n\n\u001b[32m    201\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\work\\DeepMeshCity\\testenv\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:173\u001b[39m, in \u001b[36mRandomSampler.num_samples\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnum_samples\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m    171\u001b[39m     \u001b[38;5;66;03m# dataset size might change at runtime\u001b[39;00m\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_samples\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mDataset_TPE.__len__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mxc\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.shape[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\work\\DeepMeshCity\\testenv\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:254\u001b[39m, in \u001b[36mNpzFile.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m magic == \u001b[38;5;28mformat\u001b[39m.MAGIC_PREFIX:\n\u001b[32m    253\u001b[39m     \u001b[38;5;28mbytes\u001b[39m = \u001b[38;5;28mself\u001b[39m.zip.open(key)\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.zip.read(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\work\\DeepMeshCity\\testenv\\Lib\\site-packages\\numpy\\lib\\format.py:852\u001b[39m, in \u001b[36mread_array\u001b[39m\u001b[34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[39m\n\u001b[32m    850\u001b[39m             read_size = \u001b[38;5;28mint\u001b[39m(read_count * dtype.itemsize)\n\u001b[32m    851\u001b[39m             data = _read_bytes(fp, read_size, \u001b[33m\"\u001b[39m\u001b[33marray data\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m852\u001b[39m             array[i:i+read_count] = numpy.frombuffer(data, dtype=dtype,\n\u001b[32m    853\u001b[39m                                                      count=read_count)\n\u001b[32m    855\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fortran_order:\n\u001b[32m    856\u001b[39m     array.shape = shape[::-\u001b[32m1\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_main(cfg, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb42b63",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b340d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1719, 6, 1, 28, 28) (1719, 1, 1, 28, 28) (1719, 1, 1, 28, 28) (1719, 1, 28, 28) (1719, 13) 1292.0\n",
      "checkpoint/TPE/flow/DeepMeshCity.pth\n",
      "2025-05-16 01:27:03 test...\n",
      "mse per frame: 144.23587036132812, rmse per frame: 12.0098237991333, mae per frame: 3.602595090866089, tre : 27.40910485656527 %\n",
      "The loss on test set is 144.235870\n",
      "2025-05-16 01:27:32 test...\n",
      "Saved meta_learn.0.weight to weights_txt\\meta_learn_0_weight.txt\n",
      "Saved meta_learn.2.weight to weights_txt\\meta_learn_2_weight.txt\n",
      "Saved SACGL_blocks.0.0.layer_q.weight to weights_txt\\SACGL_blocks_0_0_layer_q_weight.txt\n",
      "Saved SACGL_blocks.0.0.layer_k.weight to weights_txt\\SACGL_blocks_0_0_layer_k_weight.txt\n",
      "Saved SACGL_blocks.0.0.layer_v.weight to weights_txt\\SACGL_blocks_0_0_layer_v_weight.txt\n",
      "Saved SACGL_blocks.0.0.layer_f.weight to weights_txt\\SACGL_blocks_0_0_layer_f_weight.txt\n",
      "Saved SACGL_blocks.0.1.conv_x.0.weight to weights_txt\\SACGL_blocks_0_1_conv_x_0_weight.txt\n",
      "Saved SACGL_blocks.0.1.conv_x.1.weight to weights_txt\\SACGL_blocks_0_1_conv_x_1_weight.txt\n",
      "Saved SACGL_blocks.0.1.conv_c.0.weight to weights_txt\\SACGL_blocks_0_1_conv_c_0_weight.txt\n",
      "Saved SACGL_blocks.0.1.conv_c.1.weight to weights_txt\\SACGL_blocks_0_1_conv_c_1_weight.txt\n",
      "Saved SACGL_blocks.0.1.conv_m.0.weight to weights_txt\\SACGL_blocks_0_1_conv_m_0_weight.txt\n",
      "Saved SACGL_blocks.0.1.conv_m.1.weight to weights_txt\\SACGL_blocks_0_1_conv_m_1_weight.txt\n",
      "Saved SACGL_blocks.0.1.conv_o_c.0.weight to weights_txt\\SACGL_blocks_0_1_conv_o_c_0_weight.txt\n",
      "Saved SACGL_blocks.0.1.conv_o_c.1.weight to weights_txt\\SACGL_blocks_0_1_conv_o_c_1_weight.txt\n",
      "Saved SACGL_blocks.0.1.conv_last.weight to weights_txt\\SACGL_blocks_0_1_conv_last_weight.txt\n",
      "Saved SACGL_blocks.1.0.layer_q.weight to weights_txt\\SACGL_blocks_1_0_layer_q_weight.txt\n",
      "Saved SACGL_blocks.1.0.layer_k.weight to weights_txt\\SACGL_blocks_1_0_layer_k_weight.txt\n",
      "Saved SACGL_blocks.1.0.layer_v.weight to weights_txt\\SACGL_blocks_1_0_layer_v_weight.txt\n",
      "Saved SACGL_blocks.1.0.layer_f.weight to weights_txt\\SACGL_blocks_1_0_layer_f_weight.txt\n",
      "Saved SACGL_blocks.1.1.conv_x.0.weight to weights_txt\\SACGL_blocks_1_1_conv_x_0_weight.txt\n",
      "Saved SACGL_blocks.1.1.conv_x.1.weight to weights_txt\\SACGL_blocks_1_1_conv_x_1_weight.txt\n",
      "Saved SACGL_blocks.1.1.conv_c.0.weight to weights_txt\\SACGL_blocks_1_1_conv_c_0_weight.txt\n",
      "Saved SACGL_blocks.1.1.conv_c.1.weight to weights_txt\\SACGL_blocks_1_1_conv_c_1_weight.txt\n",
      "Saved SACGL_blocks.1.1.conv_m.0.weight to weights_txt\\SACGL_blocks_1_1_conv_m_0_weight.txt\n",
      "Saved SACGL_blocks.1.1.conv_m.1.weight to weights_txt\\SACGL_blocks_1_1_conv_m_1_weight.txt\n",
      "Saved SACGL_blocks.1.1.conv_o_c.0.weight to weights_txt\\SACGL_blocks_1_1_conv_o_c_0_weight.txt\n",
      "Saved SACGL_blocks.1.1.conv_o_c.1.weight to weights_txt\\SACGL_blocks_1_1_conv_o_c_1_weight.txt\n",
      "Saved SACGL_blocks.1.1.conv_last.weight to weights_txt\\SACGL_blocks_1_1_conv_last_weight.txt\n",
      "Saved Output_module.0.weight to weights_txt\\Output_module_0_weight.txt\n",
      "Saved Output_module.2.weight to weights_txt\\Output_module_2_weight.txt\n"
     ]
    }
   ],
   "source": [
    "test_main(cfg=cfg) # no external 75 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d657da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 6, 1, 28, 28) (168, 1, 1, 28, 28) (168, 1, 1, 28, 28) (168, 1, 28, 28) (168, 14) 1292.0\n",
      "2025-06-06 01:41:31 test...\n",
      "The loss on test set is 147.436371\n",
      "2025-06-06 01:41:46 test...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_main(cfg=cfg) # with external 10 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee5c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 6, 1, 28, 28) (168, 1, 1, 28, 28) (168, 1, 1, 28, 28) (168, 1, 28, 28) (168, 14) 1292.0\n",
      "2025-06-06 09:38:21 test...\n",
      "The loss on test set is 229.011154\n",
      "2025-06-06 09:38:34 test...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_main(cfg=cfg) # with external 150 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437afe1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 6, 1, 28, 28) (168, 1, 1, 28, 28) (168, 1, 1, 28, 28) (168, 1, 28, 28) (168, 14) 1292.0\n",
      "2025-06-06 10:09:53 test...\n",
      "The loss on test set is 229.011154\n",
      "2025-06-06 10:10:07 test...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_main(cfg=cfg) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f00737f",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f985d356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 6, 1, 28, 28) (168, 1, 1, 28, 28) (168, 1, 1, 28, 28) (168, 1, 28, 28) (168, 32) 32\n",
      "test_loader.dataset <__main__.Dataset_TPE object at 0x0000014D00016A50>\n",
      "2025-06-26 02:51:32 test...\n",
      "(32, 1, 28, 28)\n",
      "(32, 1, 28, 28)\n",
      "(32, 1, 28, 28)\n",
      "(32, 1, 28, 28)\n",
      "(32, 1, 28, 28)\n",
      "mse per frame: 0.08960811793804169, rmse per frame: 0.2993461489677429, mae per frame: 0.09273967891931534, avg_tre : 2.8061224489795866 %\n",
      "The loss on test set is 0.089608\n",
      "2025-06-26 02:53:31 test...\n",
      "\n",
      "evaluate_model_with_custom_YD: 7\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "evaluate_model_with_custom_YD: 8\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "evaluate_model_with_custom_YD: 9\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "evaluate_model_with_custom_YD: 10\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "evaluate_model_with_custom_YD: 11\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "evaluate_model_with_custom_YD: 12\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "evaluate_model_with_custom_YD: 13\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "YD shape: torch.Size([32, 32])\n",
      "[np.float32(0.00014063716), np.float32(0.000444524), np.float32(4.416704e-05), np.float32(0.0), np.float32(0.0), np.float32(0.0022942498), np.float32(0.042954132)]\n"
     ]
    }
   ],
   "source": [
    "test_main(cfg=cfg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44d5d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
